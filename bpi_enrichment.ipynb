{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb737385",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699d82e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "text_dataset_path = \"./path/to/loan_applications.csv\"\n",
    "\n",
    "keyword_map_title = {\n",
    "    \"Home improvement\": [\"home\", \"bedroom\", \"bathroom\", \"basement\", \"kitchen\", \"floor\",\n",
    "                          \"property\", \"house\", \"relocation\", \"remodel\",\n",
    "                          \"renovation\", \"apartment\"],\n",
    "    \"Student Loan\": [\"student\", \"fee\", \"university\", \"tuition\", \"school\", \"degree\", \"class\", \"grad\",\n",
    "                      \"graduate\"],\n",
    "    \"Consume\": [\"mustang\", \"car\", \"machine\", \"auto\", \"purchase\", \"replacement\", \"sport\", \"christmas\",\n",
    "                 \"game\", \"gift\", \"bike\", \"scooter\"],\n",
    "    \"Medical\": [\"hospital\", \"cancer\", \"medical\", \"doctor\", \"uninsured\",\n",
    "                 \"medicine\", \"surgery\", \"insurance\", \"drug\", \"treatment\", \"dental\"],\n",
    "    \"Vacation\": [\"vacation\", \"summer\", \"winter\", \"country\", \"travel\", \"family\", \"wedding\", \"ring\",\n",
    "                  \"swim\", \"pool\", \"hotel\"],\n",
    "    \"Consolidation\": [\"refinance\", \"debt\", \"interest\", \"consolidation\", \"banks\", \"rate\", \"cut\",\n",
    "                       \"payoff\", \"limit\", \"reduction\", \"credit\"],\n",
    "}\n",
    "\n",
    "split = [(1.0, 0.0), (0.0, 1.0), (1.0, 0.0), (0.0, 1.0), (1.0, 0.0), (0.0, 1.0)]\n",
    "\n",
    "text_dataset = pd.read_csv(text_dataset_path)\n",
    "print(\"Columns:\", text_dataset.columns.tolist())\n",
    "print(text_dataset[\"desc\"].tolist()[:50])\n",
    "print(f\"Total descriptions: {len(text_dataset)}\")\n",
    "text_dataset['desc_word_count'] = text_dataset['desc'].str.count(' ') + 1\n",
    "text_dataset = text_dataset[\n",
    "    text_dataset['desc'].notnull() & text_dataset['title'].notnull() & text_dataset['emp_title'].notnull()]\n",
    "print(f\"Descriptions after filtering: {len(text_dataset)}\")\n",
    "text_dataset = text_dataset[text_dataset['desc_word_count'] > 20]\n",
    "\n",
    "desc_list = text_dataset['desc'].tolist()\n",
    "print(f\"Descriptions after filtering: {len(desc_list)}\")\n",
    "\n",
    "# --- Categorize each description ---\n",
    "categories = list(keyword_map_title.keys())\n",
    "accepted = []\n",
    "rejected = []\n",
    "\n",
    "for desc in desc_list:\n",
    "    desc_lower = desc.lower()\n",
    "    keyword_counts = []\n",
    "    \n",
    "    # Count keyword matches per category\n",
    "    for cat, keywords in keyword_map_title.items():\n",
    "        count = sum(kw in desc_lower for kw in keywords)\n",
    "        keyword_counts.append(count)\n",
    "    \n",
    "    # Pick the category with most matches\n",
    "    max_idx = keyword_counts.index(max(keyword_counts))\n",
    "    cat = categories[max_idx]\n",
    "    label = split[max_idx]\n",
    "    \n",
    "    # Assign to accepted or rejected\n",
    "    if label == (1.0, 0.0):\n",
    "        accepted.append(desc)\n",
    "    else:\n",
    "        rejected.append(desc)\n",
    "\n",
    "print(f\"Accepted: {len(accepted)} descriptions\")\n",
    "print(f\"Rejected: {len(rejected)} descriptions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc6e4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.log.exporter.xes import exporter as xes_exporter\n",
    "from pm4py.objects.log.obj import EventLog, Trace\n",
    "import os\n",
    "import random\n",
    "\n",
    "# print current working directory\n",
    "print(\"Current Working Directory:\")\n",
    "print(os.getcwd())\n",
    "# === Configuration ===\n",
    "log_name = \"bpi_2012\"\n",
    "text_target = \"event\"\n",
    "input_xes = f\"./path/to/{log_name}.xes\"     # Path to the input .xes file\n",
    "output_xes = f\"./path/to/{log_name}_enriched_filtered_A.xes\"   # Path to save the modified .xes file\n",
    "target_activities = {\"A_Denied\", \"A_Cancelled\", \"A_DECLINED\", \"A_CANCELLED\"}  # List of activities to check\n",
    "attr_name = \"text\"\n",
    "\n",
    "\n",
    "def enrich_log(log, activity_list, attr_name=\"text\", text_target=\"case\"):\n",
    "    for trace in log:\n",
    "        # Get the activity names from the trace\n",
    "        activities_in_trace = {event[\"concept:name\"] for event in trace}\n",
    "\n",
    "        # Determine assigned value\n",
    "        value = random.choice(rejected) if activities_in_trace.intersection(activity_list) \\\n",
    "                else random.choice(accepted)\n",
    "\n",
    "        # Write attribute according to target\n",
    "        if text_target == \"event\":\n",
    "            if len(trace) > 0:\n",
    "                trace[0][attr_name] = value\n",
    "            else:\n",
    "                # Fallback for empty traces\n",
    "                trace.attributes[attr_name] = value\n",
    "        else:\n",
    "            # Default: write as case attribute\n",
    "            trace.attributes[attr_name] = value\n",
    "\n",
    "    return log\n",
    "\n",
    "def filter_log_by_prefix(log, filter_A=False, filter_O=False):\n",
    "    # --- IMPORT LOG ---\n",
    "    print(f\"Original log: {len(log)} traces, total events = {sum(len(t) for t in log)}\")\n",
    "\n",
    "    # --- FILTER OUT TRACES WITH MISSING TIMESTAMPS ---\n",
    "    filtered_traces = []\n",
    "    for trace in log:\n",
    "        has_missing = any(\"time:timestamp\" not in e or e[\"time:timestamp\"] is None for e in trace)\n",
    "        if not has_missing:\n",
    "            filtered_traces.append(trace)\n",
    "\n",
    "    # --- FILTER ACTIVITIES BASED ON PREFIX ---\n",
    "    if filter_A or filter_O:\n",
    "        prefixes_to_keep = []\n",
    "        if filter_A:\n",
    "            prefixes_to_keep.append(\"A_\")\n",
    "        if filter_O:\n",
    "            prefixes_to_keep.append(\"O_\")\n",
    "\n",
    "        filtered_traces2 = []\n",
    "        for trace in filtered_traces:\n",
    "            new_events = [e for e in trace if any(e[\"concept:name\"].startswith(p) for p in prefixes_to_keep)]\n",
    "            if len(new_events) > 0:\n",
    "                new_trace = Trace(new_events, attributes=trace.attributes)\n",
    "                filtered_traces2.append(new_trace)\n",
    "    else:\n",
    "        filtered_traces2 = filtered_traces\n",
    "\n",
    "    # --- WRAP BACK INTO EVENT LOG ---\n",
    "    clean_log = EventLog(filtered_traces2)\n",
    "    print(f\"Filtered log: {len(clean_log)} traces, total events = {sum(len(t) for t in clean_log)}\")\n",
    "\n",
    "    return clean_log\n",
    "\n",
    "print(\"Reading log...\")\n",
    "log = xes_importer.apply(input_xes)\n",
    "\n",
    "print(\"Adding binary case attribute...\")\n",
    "log = filter_log_by_prefix(log, filter_A=True, filter_O=False)\n",
    "log = enrich_log(log, target_activities, text_target=text_target, attr_name=attr_name)\n",
    "\n",
    "print(\"\\n=== First 10 Cases (for validation) ===\")\n",
    "for i, trace in enumerate(log[:10]):\n",
    "    case_id = trace.attributes.get(\"concept:name\", f\"Case_{i}\")\n",
    "    activities = [event[\"concept:name\"] for event in trace]\n",
    "    text_value = trace[0].get(\"text\", \"N/A\") if text_target == \"event\" else trace.attributes.get(\"text\", \"N/A\")\n",
    "    print(f\"Case: {case_id}\")\n",
    "    print(f\"  Activities: {activities}\")\n",
    "    print(f\"  Binary flag: {text_value}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "xes_exporter.apply(log, output_xes)\n",
    "print(f\"\\nNew case attribute added and saved to: {output_xes}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
