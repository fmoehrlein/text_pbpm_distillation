{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "558a916d",
   "metadata": {},
   "source": [
    "# Approximation through Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20d82cb",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab19460",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_488/1795954078.py:8: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing missing packages: ['sentence_transformers']\n",
      "Looking in indexes: https://nexus.iisys.de/repository/ki-awz-pypi-group/simple, https://pypi.org/simple\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.12/site-packages (5.1.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.57.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (2.9.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.7.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (1.16.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (0.36.0)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /opt/conda/lib/python3.12/site-packages (from sentence_transformers) (4.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (3.20.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.7.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.9.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (3.5.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence_transformers) (2025.8.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.6.0)\n",
      "Updating the git repository...\n",
      "Already up to date.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pkg_resources\n",
    "\n",
    "def install_missing_requirements(requirements_path):\n",
    "    if not os.path.exists(requirements_path):\n",
    "        print(f\"Requirements file '{requirements_path}' not found.\")\n",
    "        return\n",
    "\n",
    "    with open(requirements_path) as f:\n",
    "        required = [line.strip() for line in f if line.strip() and not line.startswith(\"#\")]\n",
    "\n",
    "    installed = {pkg.key for pkg in pkg_resources.working_set}\n",
    "    \n",
    "    missing = []\n",
    "    for req in required:\n",
    "        pkg_name = req.split(\"==\")[0].lower()\n",
    "        if pkg_name not in installed:\n",
    "            missing.append(req)\n",
    "\n",
    "    if not missing:\n",
    "        print(\"All required packages are already installed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Installing missing packages: {missing}\")\n",
    "\n",
    "    # Check if running inside conda\n",
    "    conda_prefix = os.environ.get(\"CONDA_PREFIX\")\n",
    "    if conda_prefix:\n",
    "        print(\"Detected conda environment. Trying to use conda first...\")\n",
    "        for pkg in missing:\n",
    "            pkg_name = pkg.split(\"==\")[0]\n",
    "            try:\n",
    "                subprocess.check_call([\"conda\", \"install\", \"-y\", pkg_name])\n",
    "            except subprocess.CalledProcessError:\n",
    "                print(f\"Package '{pkg_name}' not found in conda. Falling back to pip.\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "    else:\n",
    "        # Not in conda, use pip directly\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "\n",
    "\n",
    "def update_repository():\n",
    "    print(\"Updating the git repository...\")\n",
    "    try:\n",
    "        result = subprocess.run([\"git\", \"pull\"], capture_output=True, text=True, check=True)\n",
    "        print(result.stdout)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"Git pull failed:\")\n",
    "        print(e.stderr)\n",
    "\n",
    "# install missing requirements\n",
    "install_missing_requirements(\"/home/jovyan/requirements_reddit.txt\")\n",
    "\n",
    "# set cwd to the project root\n",
    "cwd = os.getcwd()\n",
    "wd = '/home/jovyan/reddit-mining/'\n",
    "if cwd != wd:\n",
    "    os.chdir(wd)\n",
    "\n",
    "# update the git repository\n",
    "update_repository()\n",
    "\n",
    "# set PYTHONPATH to the src directory\n",
    "sys.path.append('src')\n",
    "\n",
    "# set up logging\n",
    "from logger import setup_logger\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "#logger = setup_logger(level=logging.INFO)\n",
    "logger = setup_logger(level=logging.DEBUG)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "\n",
    "variant = xes_importer.Variants.ITERPARSE\n",
    "parameters = {\n",
    "    #variant.value.Parameters.TIMESTAMP_SORT: True,\n",
    "    #variant.value.Parameters.REVERSE_SORT: False,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbecc01",
   "metadata": {},
   "source": [
    "## Create Log Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564c4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load event log...\n",
      "Create log statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "135557ddf04f43b5985918f71a2c8993",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/13087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "12 columns passed, passed data had 11 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py:939\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m     columns = \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py:986\u001b[39m, in \u001b[36m_validate_or_indexify_columns\u001b[39m\u001b[34m(content, columns)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    987\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns passed, passed data had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    989\u001b[39m     )\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: 12 columns passed, passed data had 11 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     33\u001b[39m     docs_filtered = BoWTextEncoder().preprocess_docs(docs, as_list=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     34\u001b[39m     words_filtered = [word \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs_filtered \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_tokenize(doc, language=language)]\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     log_info = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdurations\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfromkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconcept:name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords_filtered\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwords_filtered\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlog\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcases\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrace variants\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevents\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mevents per trace\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmedian case duration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmean case duration\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mactivities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwords pre filtering\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwords post filtering\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvocabulary pre filtering\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvocabulary post filtering\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     log_info.to_csv(\u001b[33m\"\u001b[39m\u001b[33m./results/log_info.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m, sep=\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mDone.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/frame.py:851\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m         arrays,\n\u001b[32m    861\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         typ=manager,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/pandas/core/internals/construction.py:942\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    939\u001b[39m     columns = _validate_or_indexify_columns(contents, columns)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m    945\u001b[39m     contents = convert_object_array(contents, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: 12 columns passed, passed data had 11 columns"
     ]
    }
   ],
   "source": [
    "from tapp.text_encoder import BoWTextEncoder, BERTbaseTextEncoder\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "folder_names = [\"bpi_2012_enriched_filtered_A\", \"werk\"]\n",
    "\n",
    "print(\"Load event log...\")\n",
    "\n",
    "print(\"Create log statistics...\")\n",
    "for folder_name in folder_names:\n",
    "    if folder_name == \"werk\":\n",
    "        path = \"./data/werk.xes\"\n",
    "        data_attributes = [\"age\", \"gender\"]\n",
    "        text_attribute = \"question\"\n",
    "        text_models = [BERTbaseTextEncoder(encoding_length=768, language=\"english\")]\n",
    "    elif \"bpi\" in folder_name:\n",
    "        path = f\"./data/{folder_name}.xes\"\n",
    "        data_attributes = []\n",
    "        if \"special\" in folder_name:\n",
    "            text_attribute = \"binary_flag\"\n",
    "        else:\n",
    "            text_attribute = \"text\"\n",
    "        text_models = [BERTbaseTextEncoder(encoding_length=768, language=\"english\")]\n",
    "    log = xes_importer.apply(path, variant=variant, parameters=parameters)\n",
    "\n",
    "    language = \"english\"\n",
    "    traces = len(log)\n",
    "    events = sum(len(case) for case in log)\n",
    "    durations = [(case[-1][\"time:timestamp\"].timestamp() - case[0][\"time:timestamp\"].timestamp()) / 86400 for case in log]\n",
    "    docs = [event[text_attribute] for case in log for event in case if text_attribute in event]\n",
    "    words = [word for doc in docs for word in word_tokenize(doc, language=language)]\n",
    "    docs_filtered = BoWTextEncoder().preprocess_docs(docs, as_list=False)\n",
    "    words_filtered = [word for doc in docs_filtered for word in word_tokenize(doc, language=language)]\n",
    "\n",
    "    log_info = pd.DataFrame(\n",
    "        [[path,\n",
    "        traces,\n",
    "        events,\n",
    "        events / traces,\n",
    "        np.median(durations),\n",
    "        np.mean(durations),\n",
    "        len(list(dict.fromkeys([event[\"concept:name\"] for case in log for event in case])) if log else []),\n",
    "        len(words),\n",
    "        len(words_filtered),\n",
    "        len(set(words)),\n",
    "        len(set(words_filtered))]],\n",
    "        columns=[\"log\", \"cases\", \"events\", \"events per trace\", \"median case duration\",\n",
    "                \"mean case duration\", \"activities\", \"words pre filtering\", \"words post filtering\",\n",
    "                \"vocabulary pre filtering\", \"vocabulary post filtering\"]\n",
    "    )\n",
    "\n",
    "    log_info.to_csv(\"./results/log_info.csv\", index=False, sep=\";\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317c5bd",
   "metadata": {},
   "source": [
    "## Create the Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a8d8295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating the git repository...\n",
      "Already up to date.\n",
      "\n",
      "Processing folder: werk\n",
      "usingtextattribute: question\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcd6769b751413baca91b598b6fbfdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/15001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using text model: BERTbase with encoding length 768\n",
      "Fitting log encoder...\n",
      "Event encoding length: 795\n",
      "feature_dim components: activity_encoding_length = 18 , time_encoding_length = 3 , categorical_attributes_encoding_length = 6 , numerical_attributes_encoding_length = 0 , text_encoding_length = 768\n",
      "categorical_attributes_values: [['50-65', '30-39', '40-49', '18-29'], ['M', 'V']]\n",
      "Number of documents for text encoder training: 21750\n",
      "Number of unique documents: 764\n",
      "Sample documents: ['How can I add a document/share with my consultant work through the workbook?', 'Filling: What should I do if I made a mistake when filling out the Income Problem?', 'When is/are transferred my unemployment benefits?', 'General: Can you answer my question (UWV colleague)?', 'What are the consequences if I want to stop my unemployment benefit themselves?']\n",
      "self.text_encoder type: <class 'tapp.text_encoder.BERTbaseTextEncoder'>\n",
      "Transforming training data...\n",
      "Encoding log with 12000 cases...\n",
      "vecs shape: (709, 768)\n",
      "target_dim: 768\n",
      "vecs sample: [[-9.064173  -7.279898  -8.656439  ... -5.796433  -7.662382   6.61687  ]\n",
      " [ 2.1863418 -2.5088878 -2.763081  ... -2.3167014  0.4521589  4.0149517]\n",
      " [ 0.2531448 -7.193407  -3.79432   ... -1.5682118 -0.5932338  4.415711 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding log: 100%|██████████| 12000/12000 [00:01<00:00, 7032.47case/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (44241, 10, 795)\n",
      "Transforming test data...\n",
      "Encoding log with 3001 cases...\n",
      "vecs shape: (460, 768)\n",
      "target_dim: 768\n",
      "vecs sample: [[-9.064173  -7.279898  -8.656439  ... -5.796433  -7.662382   6.61687  ]\n",
      " [ 2.1863418 -2.5088878 -2.763081  ... -2.3167014  0.4521589  4.0149517]\n",
      " [ 0.2531448 -7.193407  -3.79432   ... -1.5682118 -0.5932338  4.415711 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoding log: 100%|██████████| 3001/3001 [00:00<00:00, 7608.67case/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (10979, 10, 795)\n",
      "Starting run 0...\n",
      "Training TAPPBERT model...\n",
      "building model with timesteps = 10 and feature_dim = 795\n",
      "start fitting...\n",
      "Epoch 1/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 18ms/step - loss: 1.9136 - next_activity_output_categorical_accuracy: 0.3924 - next_activity_output_loss: 1.7959 - next_timestamp_output_loss: 0.1177 - next_timestamp_output_mean_absolute_error: 0.1177 - val_loss: 1.8501 - val_next_activity_output_categorical_accuracy: 0.4111 - val_next_activity_output_loss: 1.7816 - val_next_timestamp_output_loss: 0.0691 - val_next_timestamp_output_mean_absolute_error: 0.0692 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.8267 - next_activity_output_categorical_accuracy: 0.4057 - next_activity_output_loss: 1.7490 - next_timestamp_output_loss: 0.0777 - next_timestamp_output_mean_absolute_error: 0.0777 - val_loss: 1.8274 - val_next_activity_output_categorical_accuracy: 0.4085 - val_next_activity_output_loss: 1.7610 - val_next_timestamp_output_loss: 0.0668 - val_next_timestamp_output_mean_absolute_error: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8145 - next_activity_output_categorical_accuracy: 0.4070 - next_activity_output_loss: 1.7403 - next_timestamp_output_loss: 0.0742 - next_timestamp_output_mean_absolute_error: 0.0742 - val_loss: 1.8174 - val_next_activity_output_categorical_accuracy: 0.4130 - val_next_activity_output_loss: 1.7516 - val_next_timestamp_output_loss: 0.0661 - val_next_timestamp_output_mean_absolute_error: 0.0661 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8092 - next_activity_output_categorical_accuracy: 0.4079 - next_activity_output_loss: 1.7361 - next_timestamp_output_loss: 0.0731 - next_timestamp_output_mean_absolute_error: 0.0731 - val_loss: 1.8097 - val_next_activity_output_categorical_accuracy: 0.4097 - val_next_activity_output_loss: 1.7475 - val_next_timestamp_output_loss: 0.0624 - val_next_timestamp_output_mean_absolute_error: 0.0625 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8037 - next_activity_output_categorical_accuracy: 0.4084 - next_activity_output_loss: 1.7315 - next_timestamp_output_loss: 0.0722 - next_timestamp_output_mean_absolute_error: 0.0722 - val_loss: 1.8086 - val_next_activity_output_categorical_accuracy: 0.4136 - val_next_activity_output_loss: 1.7358 - val_next_timestamp_output_loss: 0.0729 - val_next_timestamp_output_mean_absolute_error: 0.0730 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7997 - next_activity_output_categorical_accuracy: 0.4079 - next_activity_output_loss: 1.7276 - next_timestamp_output_loss: 0.0721 - next_timestamp_output_mean_absolute_error: 0.0721 - val_loss: 1.8033 - val_next_activity_output_categorical_accuracy: 0.4118 - val_next_activity_output_loss: 1.7372 - val_next_timestamp_output_loss: 0.0662 - val_next_timestamp_output_mean_absolute_error: 0.0663 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7972 - next_activity_output_categorical_accuracy: 0.4088 - next_activity_output_loss: 1.7254 - next_timestamp_output_loss: 0.0718 - next_timestamp_output_mean_absolute_error: 0.0718 - val_loss: 1.8028 - val_next_activity_output_categorical_accuracy: 0.4094 - val_next_activity_output_loss: 1.7397 - val_next_timestamp_output_loss: 0.0628 - val_next_timestamp_output_mean_absolute_error: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7955 - next_activity_output_categorical_accuracy: 0.4090 - next_activity_output_loss: 1.7237 - next_timestamp_output_loss: 0.0718 - next_timestamp_output_mean_absolute_error: 0.0718 - val_loss: 1.8121 - val_next_activity_output_categorical_accuracy: 0.4112 - val_next_activity_output_loss: 1.7403 - val_next_timestamp_output_loss: 0.0718 - val_next_timestamp_output_mean_absolute_error: 0.0718 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7961 - next_activity_output_categorical_accuracy: 0.4074 - next_activity_output_loss: 1.7244 - next_timestamp_output_loss: 0.0717 - next_timestamp_output_mean_absolute_error: 0.0717 - val_loss: 1.7944 - val_next_activity_output_categorical_accuracy: 0.4147 - val_next_activity_output_loss: 1.7315 - val_next_timestamp_output_loss: 0.0628 - val_next_timestamp_output_mean_absolute_error: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7960 - next_activity_output_categorical_accuracy: 0.4095 - next_activity_output_loss: 1.7245 - next_timestamp_output_loss: 0.0715 - next_timestamp_output_mean_absolute_error: 0.0715 - val_loss: 1.7999 - val_next_activity_output_categorical_accuracy: 0.4156 - val_next_activity_output_loss: 1.7387 - val_next_timestamp_output_loss: 0.0609 - val_next_timestamp_output_mean_absolute_error: 0.0610 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7936 - next_activity_output_categorical_accuracy: 0.4093 - next_activity_output_loss: 1.7222 - next_timestamp_output_loss: 0.0714 - next_timestamp_output_mean_absolute_error: 0.0714 - val_loss: 1.8064 - val_next_activity_output_categorical_accuracy: 0.4160 - val_next_activity_output_loss: 1.7376 - val_next_timestamp_output_loss: 0.0687 - val_next_timestamp_output_mean_absolute_error: 0.0688 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7918 - next_activity_output_categorical_accuracy: 0.4090 - next_activity_output_loss: 1.7205 - next_timestamp_output_loss: 0.0713 - next_timestamp_output_mean_absolute_error: 0.0713 - val_loss: 1.7916 - val_next_activity_output_categorical_accuracy: 0.4118 - val_next_activity_output_loss: 1.7291 - val_next_timestamp_output_loss: 0.0623 - val_next_timestamp_output_mean_absolute_error: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7903 - next_activity_output_categorical_accuracy: 0.4082 - next_activity_output_loss: 1.7191 - next_timestamp_output_loss: 0.0712 - next_timestamp_output_mean_absolute_error: 0.0712 - val_loss: 1.7887 - val_next_activity_output_categorical_accuracy: 0.4153 - val_next_activity_output_loss: 1.7268 - val_next_timestamp_output_loss: 0.0616 - val_next_timestamp_output_mean_absolute_error: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7916 - next_activity_output_categorical_accuracy: 0.4106 - next_activity_output_loss: 1.7205 - next_timestamp_output_loss: 0.0711 - next_timestamp_output_mean_absolute_error: 0.0711 - val_loss: 1.8063 - val_next_activity_output_categorical_accuracy: 0.4101 - val_next_activity_output_loss: 1.7377 - val_next_timestamp_output_loss: 0.0682 - val_next_timestamp_output_mean_absolute_error: 0.0682 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7881 - next_activity_output_categorical_accuracy: 0.4094 - next_activity_output_loss: 1.7170 - next_timestamp_output_loss: 0.0710 - next_timestamp_output_mean_absolute_error: 0.0710 - val_loss: 1.8002 - val_next_activity_output_categorical_accuracy: 0.4109 - val_next_activity_output_loss: 1.7333 - val_next_timestamp_output_loss: 0.0664 - val_next_timestamp_output_mean_absolute_error: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7878 - next_activity_output_categorical_accuracy: 0.4107 - next_activity_output_loss: 1.7169 - next_timestamp_output_loss: 0.0709 - next_timestamp_output_mean_absolute_error: 0.0709 - val_loss: 1.7978 - val_next_activity_output_categorical_accuracy: 0.4170 - val_next_activity_output_loss: 1.7307 - val_next_timestamp_output_loss: 0.0667 - val_next_timestamp_output_mean_absolute_error: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7880 - next_activity_output_categorical_accuracy: 0.4132 - next_activity_output_loss: 1.7173 - next_timestamp_output_loss: 0.0707 - next_timestamp_output_mean_absolute_error: 0.0707 - val_loss: 1.7931 - val_next_activity_output_categorical_accuracy: 0.4196 - val_next_activity_output_loss: 1.7296 - val_next_timestamp_output_loss: 0.0631 - val_next_timestamp_output_mean_absolute_error: 0.0632 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7868 - next_activity_output_categorical_accuracy: 0.4150 - next_activity_output_loss: 1.7161 - next_timestamp_output_loss: 0.0707 - next_timestamp_output_mean_absolute_error: 0.0707 - val_loss: 1.7965 - val_next_activity_output_categorical_accuracy: 0.4213 - val_next_activity_output_loss: 1.7295 - val_next_timestamp_output_loss: 0.0665 - val_next_timestamp_output_mean_absolute_error: 0.0665 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7714 - next_activity_output_categorical_accuracy: 0.4149 - next_activity_output_loss: 1.7051 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7826 - val_next_activity_output_categorical_accuracy: 0.4196 - val_next_activity_output_loss: 1.7210 - val_next_timestamp_output_loss: 0.0611 - val_next_timestamp_output_mean_absolute_error: 0.0611 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7702 - next_activity_output_categorical_accuracy: 0.4156 - next_activity_output_loss: 1.7039 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7821 - val_next_activity_output_categorical_accuracy: 0.4216 - val_next_activity_output_loss: 1.7211 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7691 - next_activity_output_categorical_accuracy: 0.4171 - next_activity_output_loss: 1.7028 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7810 - val_next_activity_output_categorical_accuracy: 0.4206 - val_next_activity_output_loss: 1.7206 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7691 - next_activity_output_categorical_accuracy: 0.4154 - next_activity_output_loss: 1.7027 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7811 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7207 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7677 - next_activity_output_categorical_accuracy: 0.4155 - next_activity_output_loss: 1.7014 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7811 - val_next_activity_output_categorical_accuracy: 0.4164 - val_next_activity_output_loss: 1.7204 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7684 - next_activity_output_categorical_accuracy: 0.4159 - next_activity_output_loss: 1.7021 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7803 - val_next_activity_output_categorical_accuracy: 0.4167 - val_next_activity_output_loss: 1.7198 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 1.7680 - next_activity_output_categorical_accuracy: 0.4154 - next_activity_output_loss: 1.7017 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7812 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7208 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7676 - next_activity_output_categorical_accuracy: 0.4170 - next_activity_output_loss: 1.7013 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7812 - val_next_activity_output_categorical_accuracy: 0.4174 - val_next_activity_output_loss: 1.7206 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7674 - next_activity_output_categorical_accuracy: 0.4174 - next_activity_output_loss: 1.7011 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7811 - val_next_activity_output_categorical_accuracy: 0.4211 - val_next_activity_output_loss: 1.7200 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7675 - next_activity_output_categorical_accuracy: 0.4180 - next_activity_output_loss: 1.7012 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7799 - val_next_activity_output_categorical_accuracy: 0.4206 - val_next_activity_output_loss: 1.7195 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7664 - next_activity_output_categorical_accuracy: 0.4177 - next_activity_output_loss: 1.7001 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7806 - val_next_activity_output_categorical_accuracy: 0.4199 - val_next_activity_output_loss: 1.7196 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7667 - next_activity_output_categorical_accuracy: 0.4155 - next_activity_output_loss: 1.7004 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7804 - val_next_activity_output_categorical_accuracy: 0.4154 - val_next_activity_output_loss: 1.7194 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7663 - next_activity_output_categorical_accuracy: 0.4161 - next_activity_output_loss: 1.7000 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7810 - val_next_activity_output_categorical_accuracy: 0.4168 - val_next_activity_output_loss: 1.7204 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7667 - next_activity_output_categorical_accuracy: 0.4177 - next_activity_output_loss: 1.7004 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7815 - val_next_activity_output_categorical_accuracy: 0.4190 - val_next_activity_output_loss: 1.7204 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7666 - next_activity_output_categorical_accuracy: 0.4168 - next_activity_output_loss: 1.7003 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7803 - val_next_activity_output_categorical_accuracy: 0.4182 - val_next_activity_output_loss: 1.7191 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7663 - next_activity_output_categorical_accuracy: 0.4161 - next_activity_output_loss: 1.7000 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7795 - val_next_activity_output_categorical_accuracy: 0.4169 - val_next_activity_output_loss: 1.7186 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7661 - next_activity_output_categorical_accuracy: 0.4163 - next_activity_output_loss: 1.6998 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7788 - val_next_activity_output_categorical_accuracy: 0.4205 - val_next_activity_output_loss: 1.7184 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7651 - next_activity_output_categorical_accuracy: 0.4171 - next_activity_output_loss: 1.6988 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7785 - val_next_activity_output_categorical_accuracy: 0.4202 - val_next_activity_output_loss: 1.7180 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7658 - next_activity_output_categorical_accuracy: 0.4153 - next_activity_output_loss: 1.6995 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7797 - val_next_activity_output_categorical_accuracy: 0.4199 - val_next_activity_output_loss: 1.7192 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7653 - next_activity_output_categorical_accuracy: 0.4159 - next_activity_output_loss: 1.6990 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7795 - val_next_activity_output_categorical_accuracy: 0.4179 - val_next_activity_output_loss: 1.7190 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7653 - next_activity_output_categorical_accuracy: 0.4165 - next_activity_output_loss: 1.6990 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7797 - val_next_activity_output_categorical_accuracy: 0.4205 - val_next_activity_output_loss: 1.7187 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7652 - next_activity_output_categorical_accuracy: 0.4181 - next_activity_output_loss: 1.6989 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7795 - val_next_activity_output_categorical_accuracy: 0.4173 - val_next_activity_output_loss: 1.7190 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7642 - next_activity_output_categorical_accuracy: 0.4161 - next_activity_output_loss: 1.6979 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7786 - val_next_activity_output_categorical_accuracy: 0.4161 - val_next_activity_output_loss: 1.7180 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7641 - next_activity_output_categorical_accuracy: 0.4175 - next_activity_output_loss: 1.6978 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7792 - val_next_activity_output_categorical_accuracy: 0.4196 - val_next_activity_output_loss: 1.7181 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7652 - next_activity_output_categorical_accuracy: 0.4166 - next_activity_output_loss: 1.6989 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7789 - val_next_activity_output_categorical_accuracy: 0.4220 - val_next_activity_output_loss: 1.7177 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7657 - next_activity_output_categorical_accuracy: 0.4172 - next_activity_output_loss: 1.6994 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7796 - val_next_activity_output_categorical_accuracy: 0.4211 - val_next_activity_output_loss: 1.7184 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7643 - next_activity_output_categorical_accuracy: 0.4183 - next_activity_output_loss: 1.6980 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7787 - val_next_activity_output_categorical_accuracy: 0.4174 - val_next_activity_output_loss: 1.7174 - val_next_timestamp_output_loss: 0.0607 - val_next_timestamp_output_mean_absolute_error: 0.0608 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7637 - next_activity_output_categorical_accuracy: 0.4185 - next_activity_output_loss: 1.6974 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7783 - val_next_activity_output_categorical_accuracy: 0.4203 - val_next_activity_output_loss: 1.7177 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7632 - next_activity_output_categorical_accuracy: 0.4166 - next_activity_output_loss: 1.6969 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7788 - val_next_activity_output_categorical_accuracy: 0.4207 - val_next_activity_output_loss: 1.7179 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7634 - next_activity_output_categorical_accuracy: 0.4168 - next_activity_output_loss: 1.6972 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7796 - val_next_activity_output_categorical_accuracy: 0.4202 - val_next_activity_output_loss: 1.7185 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7634 - next_activity_output_categorical_accuracy: 0.4186 - next_activity_output_loss: 1.6971 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7775 - val_next_activity_output_categorical_accuracy: 0.4207 - val_next_activity_output_loss: 1.7170 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7637 - next_activity_output_categorical_accuracy: 0.4165 - next_activity_output_loss: 1.6974 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7779 - val_next_activity_output_categorical_accuracy: 0.4208 - val_next_activity_output_loss: 1.7170 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1383/1383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Saved distilled training data to: data/distillation/werk/y_BERTbase_768_age,gender_question_0_train.npy\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Saved distilled test data to: data/distillation/werk/y_BERTbase_768_age,gender_question_0_test.npy\n",
      "Starting run 1...\n",
      "Training TAPPBERT model...\n",
      "building model with timesteps = 10 and feature_dim = 795\n",
      "start fitting...\n",
      "Epoch 1/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 1.9053 - next_activity_output_categorical_accuracy: 0.3923 - next_activity_output_loss: 1.7925 - next_timestamp_output_loss: 0.1128 - next_timestamp_output_mean_absolute_error: 0.1128 - val_loss: 1.8248 - val_next_activity_output_categorical_accuracy: 0.4111 - val_next_activity_output_loss: 1.7606 - val_next_timestamp_output_loss: 0.0648 - val_next_timestamp_output_mean_absolute_error: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.8257 - next_activity_output_categorical_accuracy: 0.4050 - next_activity_output_loss: 1.7474 - next_timestamp_output_loss: 0.0783 - next_timestamp_output_mean_absolute_error: 0.0783 - val_loss: 1.8171 - val_next_activity_output_categorical_accuracy: 0.4144 - val_next_activity_output_loss: 1.7522 - val_next_timestamp_output_loss: 0.0652 - val_next_timestamp_output_mean_absolute_error: 0.0652 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8135 - next_activity_output_categorical_accuracy: 0.4070 - next_activity_output_loss: 1.7381 - next_timestamp_output_loss: 0.0754 - next_timestamp_output_mean_absolute_error: 0.0754 - val_loss: 1.8203 - val_next_activity_output_categorical_accuracy: 0.4159 - val_next_activity_output_loss: 1.7537 - val_next_timestamp_output_loss: 0.0668 - val_next_timestamp_output_mean_absolute_error: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8090 - next_activity_output_categorical_accuracy: 0.4072 - next_activity_output_loss: 1.7351 - next_timestamp_output_loss: 0.0739 - next_timestamp_output_mean_absolute_error: 0.0739 - val_loss: 1.8385 - val_next_activity_output_categorical_accuracy: 0.4064 - val_next_activity_output_loss: 1.7701 - val_next_timestamp_output_loss: 0.0685 - val_next_timestamp_output_mean_absolute_error: 0.0685 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8053 - next_activity_output_categorical_accuracy: 0.4070 - next_activity_output_loss: 1.7324 - next_timestamp_output_loss: 0.0728 - next_timestamp_output_mean_absolute_error: 0.0728 - val_loss: 1.8091 - val_next_activity_output_categorical_accuracy: 0.4146 - val_next_activity_output_loss: 1.7423 - val_next_timestamp_output_loss: 0.0668 - val_next_timestamp_output_mean_absolute_error: 0.0668 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8010 - next_activity_output_categorical_accuracy: 0.4068 - next_activity_output_loss: 1.7285 - next_timestamp_output_loss: 0.0725 - next_timestamp_output_mean_absolute_error: 0.0725 - val_loss: 1.8014 - val_next_activity_output_categorical_accuracy: 0.4139 - val_next_activity_output_loss: 1.7370 - val_next_timestamp_output_loss: 0.0642 - val_next_timestamp_output_mean_absolute_error: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8056 - next_activity_output_categorical_accuracy: 0.4059 - next_activity_output_loss: 1.7335 - next_timestamp_output_loss: 0.0722 - next_timestamp_output_mean_absolute_error: 0.0722 - val_loss: 1.8223 - val_next_activity_output_categorical_accuracy: 0.4048 - val_next_activity_output_loss: 1.7550 - val_next_timestamp_output_loss: 0.0671 - val_next_timestamp_output_mean_absolute_error: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.8084 - next_activity_output_categorical_accuracy: 0.4054 - next_activity_output_loss: 1.7364 - next_timestamp_output_loss: 0.0720 - next_timestamp_output_mean_absolute_error: 0.0720 - val_loss: 1.8206 - val_next_activity_output_categorical_accuracy: 0.3976 - val_next_activity_output_loss: 1.7533 - val_next_timestamp_output_loss: 0.0671 - val_next_timestamp_output_mean_absolute_error: 0.0671 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.8085 - next_activity_output_categorical_accuracy: 0.4042 - next_activity_output_loss: 1.7365 - next_timestamp_output_loss: 0.0720 - next_timestamp_output_mean_absolute_error: 0.0720 - val_loss: 1.8206 - val_next_activity_output_categorical_accuracy: 0.4051 - val_next_activity_output_loss: 1.7498 - val_next_timestamp_output_loss: 0.0704 - val_next_timestamp_output_mean_absolute_error: 0.0704 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8084 - next_activity_output_categorical_accuracy: 0.4059 - next_activity_output_loss: 1.7365 - next_timestamp_output_loss: 0.0719 - next_timestamp_output_mean_absolute_error: 0.0719 - val_loss: 1.8134 - val_next_activity_output_categorical_accuracy: 0.4051 - val_next_activity_output_loss: 1.7478 - val_next_timestamp_output_loss: 0.0654 - val_next_timestamp_output_mean_absolute_error: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.8059 - next_activity_output_categorical_accuracy: 0.4060 - next_activity_output_loss: 1.7342 - next_timestamp_output_loss: 0.0717 - next_timestamp_output_mean_absolute_error: 0.0717 - val_loss: 1.8105 - val_next_activity_output_categorical_accuracy: 0.4054 - val_next_activity_output_loss: 1.7486 - val_next_timestamp_output_loss: 0.0616 - val_next_timestamp_output_mean_absolute_error: 0.0617 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7912 - next_activity_output_categorical_accuracy: 0.4072 - next_activity_output_loss: 1.7247 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.8016 - val_next_activity_output_categorical_accuracy: 0.4111 - val_next_activity_output_loss: 1.7413 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7892 - next_activity_output_categorical_accuracy: 0.4077 - next_activity_output_loss: 1.7227 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.8032 - val_next_activity_output_categorical_accuracy: 0.4102 - val_next_activity_output_loss: 1.7415 - val_next_timestamp_output_loss: 0.0613 - val_next_timestamp_output_mean_absolute_error: 0.0614 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7889 - next_activity_output_categorical_accuracy: 0.4084 - next_activity_output_loss: 1.7224 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.8013 - val_next_activity_output_categorical_accuracy: 0.4102 - val_next_activity_output_loss: 1.7403 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7884 - next_activity_output_categorical_accuracy: 0.4072 - next_activity_output_loss: 1.7218 - next_timestamp_output_loss: 0.0666 - next_timestamp_output_mean_absolute_error: 0.0666 - val_loss: 1.8011 - val_next_activity_output_categorical_accuracy: 0.4101 - val_next_activity_output_loss: 1.7406 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7884 - next_activity_output_categorical_accuracy: 0.4077 - next_activity_output_loss: 1.7219 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.8008 - val_next_activity_output_categorical_accuracy: 0.4103 - val_next_activity_output_loss: 1.7400 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7880 - next_activity_output_categorical_accuracy: 0.4084 - next_activity_output_loss: 1.7215 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.7997 - val_next_activity_output_categorical_accuracy: 0.4103 - val_next_activity_output_loss: 1.7391 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7874 - next_activity_output_categorical_accuracy: 0.4081 - next_activity_output_loss: 1.7209 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.7946 - val_next_activity_output_categorical_accuracy: 0.4104 - val_next_activity_output_loss: 1.7337 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7783 - next_activity_output_categorical_accuracy: 0.4101 - next_activity_output_loss: 1.7118 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.7879 - val_next_activity_output_categorical_accuracy: 0.4164 - val_next_activity_output_loss: 1.7264 - val_next_timestamp_output_loss: 0.0607 - val_next_timestamp_output_mean_absolute_error: 0.0608 - learning_rate: 1.0000e-04\n",
      "Epoch 20/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7740 - next_activity_output_categorical_accuracy: 0.4120 - next_activity_output_loss: 1.7075 - next_timestamp_output_loss: 0.0665 - next_timestamp_output_mean_absolute_error: 0.0665 - val_loss: 1.7822 - val_next_activity_output_categorical_accuracy: 0.4197 - val_next_activity_output_loss: 1.7214 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 21/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7716 - next_activity_output_categorical_accuracy: 0.4132 - next_activity_output_loss: 1.7052 - next_timestamp_output_loss: 0.0664 - next_timestamp_output_mean_absolute_error: 0.0664 - val_loss: 1.7833 - val_next_activity_output_categorical_accuracy: 0.4152 - val_next_activity_output_loss: 1.7219 - val_next_timestamp_output_loss: 0.0607 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 22/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7698 - next_activity_output_categorical_accuracy: 0.4161 - next_activity_output_loss: 1.7034 - next_timestamp_output_loss: 0.0664 - next_timestamp_output_mean_absolute_error: 0.0664 - val_loss: 1.7799 - val_next_activity_output_categorical_accuracy: 0.4179 - val_next_activity_output_loss: 1.7186 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 23/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7683 - next_activity_output_categorical_accuracy: 0.4159 - next_activity_output_loss: 1.7020 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7784 - val_next_activity_output_categorical_accuracy: 0.4225 - val_next_activity_output_loss: 1.7173 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7675 - next_activity_output_categorical_accuracy: 0.4172 - next_activity_output_loss: 1.7012 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7801 - val_next_activity_output_categorical_accuracy: 0.4215 - val_next_activity_output_loss: 1.7186 - val_next_timestamp_output_loss: 0.0608 - val_next_timestamp_output_mean_absolute_error: 0.0608 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7665 - next_activity_output_categorical_accuracy: 0.4166 - next_activity_output_loss: 1.7002 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7757 - val_next_activity_output_categorical_accuracy: 0.4211 - val_next_activity_output_loss: 1.7148 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7656 - next_activity_output_categorical_accuracy: 0.4169 - next_activity_output_loss: 1.6992 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7759 - val_next_activity_output_categorical_accuracy: 0.4200 - val_next_activity_output_loss: 1.7146 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7649 - next_activity_output_categorical_accuracy: 0.4180 - next_activity_output_loss: 1.6986 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7765 - val_next_activity_output_categorical_accuracy: 0.4193 - val_next_activity_output_loss: 1.7152 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7629 - next_activity_output_categorical_accuracy: 0.4177 - next_activity_output_loss: 1.6966 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7734 - val_next_activity_output_categorical_accuracy: 0.4231 - val_next_activity_output_loss: 1.7124 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7612 - next_activity_output_categorical_accuracy: 0.4180 - next_activity_output_loss: 1.6949 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7723 - val_next_activity_output_categorical_accuracy: 0.4251 - val_next_activity_output_loss: 1.7114 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7609 - next_activity_output_categorical_accuracy: 0.4182 - next_activity_output_loss: 1.6946 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7724 - val_next_activity_output_categorical_accuracy: 0.4228 - val_next_activity_output_loss: 1.7116 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7592 - next_activity_output_categorical_accuracy: 0.4204 - next_activity_output_loss: 1.6930 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7702 - val_next_activity_output_categorical_accuracy: 0.4242 - val_next_activity_output_loss: 1.7094 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7587 - next_activity_output_categorical_accuracy: 0.4215 - next_activity_output_loss: 1.6924 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7706 - val_next_activity_output_categorical_accuracy: 0.4222 - val_next_activity_output_loss: 1.7094 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7569 - next_activity_output_categorical_accuracy: 0.4204 - next_activity_output_loss: 1.6907 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7704 - val_next_activity_output_categorical_accuracy: 0.4187 - val_next_activity_output_loss: 1.7093 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7568 - next_activity_output_categorical_accuracy: 0.4197 - next_activity_output_loss: 1.6906 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7685 - val_next_activity_output_categorical_accuracy: 0.4234 - val_next_activity_output_loss: 1.7076 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7548 - next_activity_output_categorical_accuracy: 0.4216 - next_activity_output_loss: 1.6887 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7683 - val_next_activity_output_categorical_accuracy: 0.4208 - val_next_activity_output_loss: 1.7068 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7553 - next_activity_output_categorical_accuracy: 0.4197 - next_activity_output_loss: 1.6891 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7672 - val_next_activity_output_categorical_accuracy: 0.4236 - val_next_activity_output_loss: 1.7053 - val_next_timestamp_output_loss: 0.0610 - val_next_timestamp_output_mean_absolute_error: 0.0611 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - loss: 1.7544 - next_activity_output_categorical_accuracy: 0.4209 - next_activity_output_loss: 1.6882 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7662 - val_next_activity_output_categorical_accuracy: 0.4247 - val_next_activity_output_loss: 1.7055 - val_next_timestamp_output_loss: 0.0598 - val_next_timestamp_output_mean_absolute_error: 0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7525 - next_activity_output_categorical_accuracy: 0.4217 - next_activity_output_loss: 1.6863 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7646 - val_next_activity_output_categorical_accuracy: 0.4228 - val_next_activity_output_loss: 1.7035 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7526 - next_activity_output_categorical_accuracy: 0.4216 - next_activity_output_loss: 1.6865 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7663 - val_next_activity_output_categorical_accuracy: 0.4236 - val_next_activity_output_loss: 1.7050 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7511 - next_activity_output_categorical_accuracy: 0.4223 - next_activity_output_loss: 1.6850 - next_timestamp_output_loss: 0.0662 - next_timestamp_output_mean_absolute_error: 0.0662 - val_loss: 1.7637 - val_next_activity_output_categorical_accuracy: 0.4241 - val_next_activity_output_loss: 1.7030 - val_next_timestamp_output_loss: 0.0598 - val_next_timestamp_output_mean_absolute_error: 0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7503 - next_activity_output_categorical_accuracy: 0.4210 - next_activity_output_loss: 1.6841 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7623 - val_next_activity_output_categorical_accuracy: 0.4248 - val_next_activity_output_loss: 1.7017 - val_next_timestamp_output_loss: 0.0597 - val_next_timestamp_output_mean_absolute_error: 0.0598 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7499 - next_activity_output_categorical_accuracy: 0.4226 - next_activity_output_loss: 1.6838 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7612 - val_next_activity_output_categorical_accuracy: 0.4274 - val_next_activity_output_loss: 1.7000 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7493 - next_activity_output_categorical_accuracy: 0.4206 - next_activity_output_loss: 1.6832 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7628 - val_next_activity_output_categorical_accuracy: 0.4245 - val_next_activity_output_loss: 1.7015 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7477 - next_activity_output_categorical_accuracy: 0.4233 - next_activity_output_loss: 1.6815 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7618 - val_next_activity_output_categorical_accuracy: 0.4233 - val_next_activity_output_loss: 1.7002 - val_next_timestamp_output_loss: 0.0607 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7466 - next_activity_output_categorical_accuracy: 0.4211 - next_activity_output_loss: 1.6805 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7632 - val_next_activity_output_categorical_accuracy: 0.4222 - val_next_activity_output_loss: 1.7019 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7473 - next_activity_output_categorical_accuracy: 0.4217 - next_activity_output_loss: 1.6813 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7607 - val_next_activity_output_categorical_accuracy: 0.4232 - val_next_activity_output_loss: 1.6996 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7456 - next_activity_output_categorical_accuracy: 0.4230 - next_activity_output_loss: 1.6795 - next_timestamp_output_loss: 0.0661 - next_timestamp_output_mean_absolute_error: 0.0661 - val_loss: 1.7589 - val_next_activity_output_categorical_accuracy: 0.4232 - val_next_activity_output_loss: 1.6981 - val_next_timestamp_output_loss: 0.0598 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.7455 - next_activity_output_categorical_accuracy: 0.4221 - next_activity_output_loss: 1.6794 - next_timestamp_output_loss: 0.0660 - next_timestamp_output_mean_absolute_error: 0.0660 - val_loss: 1.7612 - val_next_activity_output_categorical_accuracy: 0.4252 - val_next_activity_output_loss: 1.6997 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7427 - next_activity_output_categorical_accuracy: 0.4225 - next_activity_output_loss: 1.6767 - next_timestamp_output_loss: 0.0660 - next_timestamp_output_mean_absolute_error: 0.0660 - val_loss: 1.7610 - val_next_activity_output_categorical_accuracy: 0.4252 - val_next_activity_output_loss: 1.6998 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - loss: 1.7425 - next_activity_output_categorical_accuracy: 0.4218 - next_activity_output_loss: 1.6765 - next_timestamp_output_loss: 0.0660 - next_timestamp_output_mean_absolute_error: 0.0660 - val_loss: 1.7603 - val_next_activity_output_categorical_accuracy: 0.4239 - val_next_activity_output_loss: 1.6984 - val_next_timestamp_output_loss: 0.0610 - val_next_timestamp_output_mean_absolute_error: 0.0610 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1383/1383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Saved distilled training data to: data/distillation/werk/y_BERTbase_768_age,gender_question_1_train.npy\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Saved distilled test data to: data/distillation/werk/y_BERTbase_768_age,gender_question_1_test.npy\n",
      "Starting run 2...\n",
      "Training TAPPBERT model...\n",
      "building model with timesteps = 10 and feature_dim = 795\n",
      "start fitting...\n",
      "Epoch 1/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 17ms/step - loss: 1.9117 - next_activity_output_categorical_accuracy: 0.3913 - next_activity_output_loss: 1.7974 - next_timestamp_output_loss: 0.1143 - next_timestamp_output_mean_absolute_error: 0.1143 - val_loss: 1.8475 - val_next_activity_output_categorical_accuracy: 0.4074 - val_next_activity_output_loss: 1.7574 - val_next_timestamp_output_loss: 0.0908 - val_next_timestamp_output_mean_absolute_error: 0.0908 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8294 - next_activity_output_categorical_accuracy: 0.4027 - next_activity_output_loss: 1.7517 - next_timestamp_output_loss: 0.0777 - next_timestamp_output_mean_absolute_error: 0.0777 - val_loss: 1.8156 - val_next_activity_output_categorical_accuracy: 0.4112 - val_next_activity_output_loss: 1.7510 - val_next_timestamp_output_loss: 0.0648 - val_next_timestamp_output_mean_absolute_error: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 17ms/step - loss: 1.8189 - next_activity_output_categorical_accuracy: 0.4054 - next_activity_output_loss: 1.7443 - next_timestamp_output_loss: 0.0747 - next_timestamp_output_mean_absolute_error: 0.0747 - val_loss: 1.8136 - val_next_activity_output_categorical_accuracy: 0.4099 - val_next_activity_output_loss: 1.7512 - val_next_timestamp_output_loss: 0.0628 - val_next_timestamp_output_mean_absolute_error: 0.0629 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8131 - next_activity_output_categorical_accuracy: 0.4051 - next_activity_output_loss: 1.7401 - next_timestamp_output_loss: 0.0730 - next_timestamp_output_mean_absolute_error: 0.0730 - val_loss: 1.8040 - val_next_activity_output_categorical_accuracy: 0.4147 - val_next_activity_output_loss: 1.7420 - val_next_timestamp_output_loss: 0.0623 - val_next_timestamp_output_mean_absolute_error: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8062 - next_activity_output_categorical_accuracy: 0.4074 - next_activity_output_loss: 1.7336 - next_timestamp_output_loss: 0.0726 - next_timestamp_output_mean_absolute_error: 0.0726 - val_loss: 1.8118 - val_next_activity_output_categorical_accuracy: 0.4098 - val_next_activity_output_loss: 1.7422 - val_next_timestamp_output_loss: 0.0696 - val_next_timestamp_output_mean_absolute_error: 0.0696 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.8034 - next_activity_output_categorical_accuracy: 0.4087 - next_activity_output_loss: 1.7311 - next_timestamp_output_loss: 0.0723 - next_timestamp_output_mean_absolute_error: 0.0723 - val_loss: 1.8120 - val_next_activity_output_categorical_accuracy: 0.4076 - val_next_activity_output_loss: 1.7511 - val_next_timestamp_output_loss: 0.0607 - val_next_timestamp_output_mean_absolute_error: 0.0607 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7986 - next_activity_output_categorical_accuracy: 0.4093 - next_activity_output_loss: 1.7265 - next_timestamp_output_loss: 0.0721 - next_timestamp_output_mean_absolute_error: 0.0721 - val_loss: 1.7990 - val_next_activity_output_categorical_accuracy: 0.4143 - val_next_activity_output_loss: 1.7338 - val_next_timestamp_output_loss: 0.0649 - val_next_timestamp_output_mean_absolute_error: 0.0649 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7977 - next_activity_output_categorical_accuracy: 0.4098 - next_activity_output_loss: 1.7259 - next_timestamp_output_loss: 0.0719 - next_timestamp_output_mean_absolute_error: 0.0719 - val_loss: 1.8043 - val_next_activity_output_categorical_accuracy: 0.4158 - val_next_activity_output_loss: 1.7421 - val_next_timestamp_output_loss: 0.0621 - val_next_timestamp_output_mean_absolute_error: 0.0622 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7949 - next_activity_output_categorical_accuracy: 0.4106 - next_activity_output_loss: 1.7233 - next_timestamp_output_loss: 0.0716 - next_timestamp_output_mean_absolute_error: 0.0716 - val_loss: 1.8021 - val_next_activity_output_categorical_accuracy: 0.4146 - val_next_activity_output_loss: 1.7415 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7940 - next_activity_output_categorical_accuracy: 0.4114 - next_activity_output_loss: 1.7222 - next_timestamp_output_loss: 0.0718 - next_timestamp_output_mean_absolute_error: 0.0718 - val_loss: 1.7977 - val_next_activity_output_categorical_accuracy: 0.4135 - val_next_activity_output_loss: 1.7332 - val_next_timestamp_output_loss: 0.0642 - val_next_timestamp_output_mean_absolute_error: 0.0642 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7914 - next_activity_output_categorical_accuracy: 0.4130 - next_activity_output_loss: 1.7195 - next_timestamp_output_loss: 0.0719 - next_timestamp_output_mean_absolute_error: 0.0719 - val_loss: 1.8153 - val_next_activity_output_categorical_accuracy: 0.4093 - val_next_activity_output_loss: 1.7448 - val_next_timestamp_output_loss: 0.0702 - val_next_timestamp_output_mean_absolute_error: 0.0703 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7913 - next_activity_output_categorical_accuracy: 0.4107 - next_activity_output_loss: 1.7197 - next_timestamp_output_loss: 0.0716 - next_timestamp_output_mean_absolute_error: 0.0716 - val_loss: 1.7997 - val_next_activity_output_categorical_accuracy: 0.4162 - val_next_activity_output_loss: 1.7341 - val_next_timestamp_output_loss: 0.0653 - val_next_timestamp_output_mean_absolute_error: 0.0654 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7899 - next_activity_output_categorical_accuracy: 0.4111 - next_activity_output_loss: 1.7184 - next_timestamp_output_loss: 0.0715 - next_timestamp_output_mean_absolute_error: 0.0715 - val_loss: 1.7953 - val_next_activity_output_categorical_accuracy: 0.4142 - val_next_activity_output_loss: 1.7286 - val_next_timestamp_output_loss: 0.0664 - val_next_timestamp_output_mean_absolute_error: 0.0664 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7876 - next_activity_output_categorical_accuracy: 0.4121 - next_activity_output_loss: 1.7161 - next_timestamp_output_loss: 0.0715 - next_timestamp_output_mean_absolute_error: 0.0715 - val_loss: 1.7988 - val_next_activity_output_categorical_accuracy: 0.4163 - val_next_activity_output_loss: 1.7294 - val_next_timestamp_output_loss: 0.0690 - val_next_timestamp_output_mean_absolute_error: 0.0691 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7863 - next_activity_output_categorical_accuracy: 0.4107 - next_activity_output_loss: 1.7150 - next_timestamp_output_loss: 0.0713 - next_timestamp_output_mean_absolute_error: 0.0713 - val_loss: 1.7921 - val_next_activity_output_categorical_accuracy: 0.4132 - val_next_activity_output_loss: 1.7243 - val_next_timestamp_output_loss: 0.0672 - val_next_timestamp_output_mean_absolute_error: 0.0673 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7858 - next_activity_output_categorical_accuracy: 0.4110 - next_activity_output_loss: 1.7144 - next_timestamp_output_loss: 0.0714 - next_timestamp_output_mean_absolute_error: 0.0714 - val_loss: 1.7921 - val_next_activity_output_categorical_accuracy: 0.4092 - val_next_activity_output_loss: 1.7278 - val_next_timestamp_output_loss: 0.0638 - val_next_timestamp_output_mean_absolute_error: 0.0638 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7844 - next_activity_output_categorical_accuracy: 0.4127 - next_activity_output_loss: 1.7130 - next_timestamp_output_loss: 0.0713 - next_timestamp_output_mean_absolute_error: 0.0713 - val_loss: 1.7845 - val_next_activity_output_categorical_accuracy: 0.4216 - val_next_activity_output_loss: 1.7216 - val_next_timestamp_output_loss: 0.0622 - val_next_timestamp_output_mean_absolute_error: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7879 - next_activity_output_categorical_accuracy: 0.4109 - next_activity_output_loss: 1.7166 - next_timestamp_output_loss: 0.0713 - next_timestamp_output_mean_absolute_error: 0.0713 - val_loss: 1.7963 - val_next_activity_output_categorical_accuracy: 0.4178 - val_next_activity_output_loss: 1.7337 - val_next_timestamp_output_loss: 0.0622 - val_next_timestamp_output_mean_absolute_error: 0.0623 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7902 - next_activity_output_categorical_accuracy: 0.4126 - next_activity_output_loss: 1.7189 - next_timestamp_output_loss: 0.0713 - next_timestamp_output_mean_absolute_error: 0.0713 - val_loss: 1.8134 - val_next_activity_output_categorical_accuracy: 0.4103 - val_next_activity_output_loss: 1.7411 - val_next_timestamp_output_loss: 0.0719 - val_next_timestamp_output_mean_absolute_error: 0.0719 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7930 - next_activity_output_categorical_accuracy: 0.4093 - next_activity_output_loss: 1.7218 - next_timestamp_output_loss: 0.0712 - next_timestamp_output_mean_absolute_error: 0.0712 - val_loss: 1.7960 - val_next_activity_output_categorical_accuracy: 0.4107 - val_next_activity_output_loss: 1.7347 - val_next_timestamp_output_loss: 0.0608 - val_next_timestamp_output_mean_absolute_error: 0.0609 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7861 - next_activity_output_categorical_accuracy: 0.4122 - next_activity_output_loss: 1.7150 - next_timestamp_output_loss: 0.0711 - next_timestamp_output_mean_absolute_error: 0.0711 - val_loss: 1.7895 - val_next_activity_output_categorical_accuracy: 0.4170 - val_next_activity_output_loss: 1.7241 - val_next_timestamp_output_loss: 0.0648 - val_next_timestamp_output_mean_absolute_error: 0.0648 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7805 - next_activity_output_categorical_accuracy: 0.4145 - next_activity_output_loss: 1.7093 - next_timestamp_output_loss: 0.0712 - next_timestamp_output_mean_absolute_error: 0.0712 - val_loss: 1.7945 - val_next_activity_output_categorical_accuracy: 0.4148 - val_next_activity_output_loss: 1.7215 - val_next_timestamp_output_loss: 0.0723 - val_next_timestamp_output_mean_absolute_error: 0.0723 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7646 - next_activity_output_categorical_accuracy: 0.4160 - next_activity_output_loss: 1.6982 - next_timestamp_output_loss: 0.0664 - next_timestamp_output_mean_absolute_error: 0.0664 - val_loss: 1.7770 - val_next_activity_output_categorical_accuracy: 0.4196 - val_next_activity_output_loss: 1.7163 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 24/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7636 - next_activity_output_categorical_accuracy: 0.4178 - next_activity_output_loss: 1.6973 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7780 - val_next_activity_output_categorical_accuracy: 0.4178 - val_next_activity_output_loss: 1.7165 - val_next_timestamp_output_loss: 0.0608 - val_next_timestamp_output_mean_absolute_error: 0.0608 - learning_rate: 1.0000e-04\n",
      "Epoch 25/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7631 - next_activity_output_categorical_accuracy: 0.4173 - next_activity_output_loss: 1.6968 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7765 - val_next_activity_output_categorical_accuracy: 0.4206 - val_next_activity_output_loss: 1.7152 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 26/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7631 - next_activity_output_categorical_accuracy: 0.4176 - next_activity_output_loss: 1.6968 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7761 - val_next_activity_output_categorical_accuracy: 0.4184 - val_next_activity_output_loss: 1.7154 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 27/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7625 - next_activity_output_categorical_accuracy: 0.4178 - next_activity_output_loss: 1.6962 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7760 - val_next_activity_output_categorical_accuracy: 0.4182 - val_next_activity_output_loss: 1.7152 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 28/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7618 - next_activity_output_categorical_accuracy: 0.4177 - next_activity_output_loss: 1.6955 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7756 - val_next_activity_output_categorical_accuracy: 0.4199 - val_next_activity_output_loss: 1.7147 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 29/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7617 - next_activity_output_categorical_accuracy: 0.4182 - next_activity_output_loss: 1.6954 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7756 - val_next_activity_output_categorical_accuracy: 0.4206 - val_next_activity_output_loss: 1.7146 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 30/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7614 - next_activity_output_categorical_accuracy: 0.4181 - next_activity_output_loss: 1.6951 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7758 - val_next_activity_output_categorical_accuracy: 0.4178 - val_next_activity_output_loss: 1.7148 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 31/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7614 - next_activity_output_categorical_accuracy: 0.4164 - next_activity_output_loss: 1.6951 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7757 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7143 - val_next_timestamp_output_loss: 0.0606 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 32/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7617 - next_activity_output_categorical_accuracy: 0.4176 - next_activity_output_loss: 1.6954 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7757 - val_next_activity_output_categorical_accuracy: 0.4187 - val_next_activity_output_loss: 1.7138 - val_next_timestamp_output_loss: 0.0610 - val_next_timestamp_output_mean_absolute_error: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 33/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7603 - next_activity_output_categorical_accuracy: 0.4178 - next_activity_output_loss: 1.6940 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7761 - val_next_activity_output_categorical_accuracy: 0.4179 - val_next_activity_output_loss: 1.7149 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0603 - learning_rate: 1.0000e-04\n",
      "Epoch 34/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7614 - next_activity_output_categorical_accuracy: 0.4169 - next_activity_output_loss: 1.6951 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7767 - val_next_activity_output_categorical_accuracy: 0.4177 - val_next_activity_output_loss: 1.7153 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 35/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7601 - next_activity_output_categorical_accuracy: 0.4168 - next_activity_output_loss: 1.6938 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7750 - val_next_activity_output_categorical_accuracy: 0.4202 - val_next_activity_output_loss: 1.7140 - val_next_timestamp_output_loss: 0.0602 - val_next_timestamp_output_mean_absolute_error: 0.0602 - learning_rate: 1.0000e-04\n",
      "Epoch 36/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7606 - next_activity_output_categorical_accuracy: 0.4179 - next_activity_output_loss: 1.6942 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7757 - val_next_activity_output_categorical_accuracy: 0.4180 - val_next_activity_output_loss: 1.7149 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 37/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7603 - next_activity_output_categorical_accuracy: 0.4176 - next_activity_output_loss: 1.6940 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7755 - val_next_activity_output_categorical_accuracy: 0.4179 - val_next_activity_output_loss: 1.7146 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7596 - next_activity_output_categorical_accuracy: 0.4182 - next_activity_output_loss: 1.6933 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7756 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7147 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7597 - next_activity_output_categorical_accuracy: 0.4173 - next_activity_output_loss: 1.6934 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7727 - val_next_activity_output_categorical_accuracy: 0.4203 - val_next_activity_output_loss: 1.7119 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7592 - next_activity_output_categorical_accuracy: 0.4174 - next_activity_output_loss: 1.6928 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7735 - val_next_activity_output_categorical_accuracy: 0.4198 - val_next_activity_output_loss: 1.7127 - val_next_timestamp_output_loss: 0.0600 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7595 - next_activity_output_categorical_accuracy: 0.4173 - next_activity_output_loss: 1.6932 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7738 - val_next_activity_output_categorical_accuracy: 0.4184 - val_next_activity_output_loss: 1.7130 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7590 - next_activity_output_categorical_accuracy: 0.4159 - next_activity_output_loss: 1.6927 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7746 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7138 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0600 - learning_rate: 1.0000e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7591 - next_activity_output_categorical_accuracy: 0.4168 - next_activity_output_loss: 1.6927 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7745 - val_next_activity_output_categorical_accuracy: 0.4203 - val_next_activity_output_loss: 1.7132 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0605 - learning_rate: 1.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7588 - next_activity_output_categorical_accuracy: 0.4198 - next_activity_output_loss: 1.6925 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7735 - val_next_activity_output_categorical_accuracy: 0.4206 - val_next_activity_output_loss: 1.7127 - val_next_timestamp_output_loss: 0.0599 - val_next_timestamp_output_mean_absolute_error: 0.0599 - learning_rate: 1.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7588 - next_activity_output_categorical_accuracy: 0.4176 - next_activity_output_loss: 1.6925 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7747 - val_next_activity_output_categorical_accuracy: 0.4181 - val_next_activity_output_loss: 1.7135 - val_next_timestamp_output_loss: 0.0604 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7583 - next_activity_output_categorical_accuracy: 0.4177 - next_activity_output_loss: 1.6920 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7741 - val_next_activity_output_categorical_accuracy: 0.4189 - val_next_activity_output_loss: 1.7127 - val_next_timestamp_output_loss: 0.0605 - val_next_timestamp_output_mean_absolute_error: 0.0606 - learning_rate: 1.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7585 - next_activity_output_categorical_accuracy: 0.4184 - next_activity_output_loss: 1.6922 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7752 - val_next_activity_output_categorical_accuracy: 0.4204 - val_next_activity_output_loss: 1.7133 - val_next_timestamp_output_loss: 0.0610 - val_next_timestamp_output_mean_absolute_error: 0.0610 - learning_rate: 1.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 16ms/step - loss: 1.7585 - next_activity_output_categorical_accuracy: 0.4167 - next_activity_output_loss: 1.6922 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7746 - val_next_activity_output_categorical_accuracy: 0.4211 - val_next_activity_output_loss: 1.7134 - val_next_timestamp_output_loss: 0.0603 - val_next_timestamp_output_mean_absolute_error: 0.0604 - learning_rate: 1.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m1106/1106\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 16ms/step - loss: 1.7597 - next_activity_output_categorical_accuracy: 0.4175 - next_activity_output_loss: 1.6934 - next_timestamp_output_loss: 0.0663 - next_timestamp_output_mean_absolute_error: 0.0663 - val_loss: 1.7737 - val_next_activity_output_categorical_accuracy: 0.4182 - val_next_activity_output_loss: 1.7128 - val_next_timestamp_output_loss: 0.0601 - val_next_timestamp_output_mean_absolute_error: 0.0601 - learning_rate: 1.0000e-04\n",
      "\u001b[1m1383/1383\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step\n",
      "Saved distilled training data to: data/distillation/werk/y_BERTbase_768_age,gender_question_2_train.npy\n",
      "\u001b[1m344/344\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Saved distilled test data to: data/distillation/werk/y_BERTbase_768_age,gender_question_2_test.npy\n"
     ]
    }
   ],
   "source": [
    "update_repository()\n",
    "# from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from tapp.tapp_model import _get_event_labels, TappModel\n",
    "from tapp.log_encoder import LogEncoder\n",
    "from tapp.tapp_model import TappModel, _get_event_labels\n",
    "from tapp.text_encoder import BoWTextEncoder\n",
    "from tapp.text_encoder import BoNGTextEncoder\n",
    "from tapp.text_encoder import LDATextEncoder\n",
    "from tapp.text_encoder import BERTbaseTextEncoder\n",
    "from tapp.text_encoder import BERTbaseFineTunedNextActivityTextEncoder\n",
    "from distillation import get_distillation_paths\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "\n",
    "runs = 3\n",
    "folder_names = [\"bpi_2012_enriched_special_filtered_A\"]\n",
    "folder_names = [\"bpi_2012_enriched_special_filtered_A\"]\n",
    "folder_names = [\"bpi_2012_enriched_event\"]\n",
    "folder_names = [\"bpi_2012_enriched_filtered_A\", \"werk\"]\n",
    "folder_names = [\"werk\"]\n",
    "force_recompute = True\n",
    "\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    print(\"Processing folder:\", folder_name)\n",
    "\n",
    "    if folder_name == \"werk\":\n",
    "        path = \"./data/werk.xes\"\n",
    "        data_attributes = [\"age\", \"gender\"]\n",
    "        text_attribute = \"question\"\n",
    "        text_models = [BERTbaseTextEncoder(encoding_length=768, language=\"english\")]\n",
    "    elif \"bpi\" in folder_name:\n",
    "        path = f\"./data/{folder_name}.xes\"\n",
    "        data_attributes = []\n",
    "        if \"special\" in folder_name:\n",
    "            text_attribute = \"binary_flag\"\n",
    "        else:\n",
    "            text_attribute = \"text\"\n",
    "        text_models = [BERTbaseTextEncoder(encoding_length=768, language=\"english\")]\n",
    "\n",
    "    print(\"usingtextattribute:\", text_attribute)\n",
    "    log = xes_importer.apply(path, variant=variant, parameters=parameters)\n",
    "    activities = _get_event_labels(log, \"concept:name\")\n",
    "    class_names = _get_event_labels(log, \"concept:name\")\n",
    "    class_names.append(\"END\")\n",
    "    split = len(log) // 5 * 4\n",
    "    train_log = log[:split]\n",
    "    test_log = log[split:]\n",
    "\n",
    "    for text_model in text_models:\n",
    "        print(f\"Using text model: {text_model.name} with encoding length {text_model.encoding_length}\")\n",
    "\n",
    "        # initialize and fit the log encoder\n",
    "        log_encoder = LogEncoder(\n",
    "            text_encoder=text_model,\n",
    "            advanced_time_attributes=True,\n",
    "            text_base_for_training=\"event\",\n",
    "        )\n",
    "        print(\"Fitting log encoder...\")\n",
    "        log_encoder.fit(\n",
    "            log,\n",
    "            activities=activities,\n",
    "            data_attributes=data_attributes,\n",
    "            text_attribute=text_attribute,\n",
    "        )\n",
    "\n",
    "        print(\"Transforming training data...\")\n",
    "        X_train, y_train_act, y_train_time = log_encoder.transform(train_log, for_training=True)\n",
    "        print(\"X_train shape:\", X_train.shape)\n",
    "        print(\"Transforming test data...\")\n",
    "        X_test, y_test, _ = log_encoder.transform(test_log, for_training=True)\n",
    "        print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "        # tappbert original hyperparameters\n",
    "        shared_layer = 1\n",
    "        special_layer = 1\n",
    "        neuron = 100\n",
    "        epochs = 25\n",
    "        # test for lars\n",
    "        shared_layer = 2\n",
    "        special_layer = 1\n",
    "        neuron = 150\n",
    "        epochs = 50\n",
    "\n",
    "        for run_id in range(runs):\n",
    "            distillation_path_train, distillation_path_test = get_distillation_paths(folder_name, text_model, data_attributes, text_attribute, run_id)\n",
    "            if os.path.exists(distillation_path_train) and os.path.exists(distillation_path_test) and not force_recompute:\n",
    "                print(\"Skipping run\", run_id, \"as distilled training data already exists at:\", distillation_path_train)\n",
    "                continue\n",
    "            print(f\"Starting run {run_id}...\")\n",
    "            # tappbert training and evaluation\n",
    "            tapp_model = TappModel(\n",
    "                log_encoder=log_encoder,\n",
    "                num_shared_layer=shared_layer,\n",
    "                num_specialized_layer=special_layer,\n",
    "                neurons_per_layer=neuron,\n",
    "                dropout=0.2,\n",
    "                learning_rate=0.001,\n",
    "                use_lr_reduction=True,\n",
    "            )\n",
    "            tapp_model.activities = activities\n",
    "            print(\"Training TAPPBERT model...\")\n",
    "            tapp_model.fit_with_ready_data(X_train, y_train_act, y_train_time, epochs=epochs)\n",
    "\n",
    "            y_train_distilled = tapp_model.model.predict(X_train)\n",
    "            y_train_distilled = y_train_distilled[0]\n",
    "            np.save(distillation_path_train, y_train_distilled)\n",
    "            print(\"Saved distilled training data to:\", distillation_path_train)\n",
    "            y_test_distilled = tapp_model.model.predict(X_test)\n",
    "            y_test_distilled = y_test_distilled[0]\n",
    "            np.save(distillation_path_test, y_test_distilled)\n",
    "            print(\"Saved distilled test data to:\", distillation_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d7ccae",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28f0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating the git repository...\n",
      "Already up to date.\n",
      "\n",
      "Evaluating folder: bpi_2012_enriched_filtered_A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77932152ac934cb3a5bde4fbc22cbf76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "parsing log, completed traces ::   0%|          | 0/13087 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log split at index: 10468\n",
      "Loading distilled labels for run 0...\n",
      "Distillation paths: data/distillation/bpi_2012_enriched_filtered_A/y_BERTbase_768_None_text_0_train.npy data/distillation/bpi_2012_enriched_filtered_A/y_BERTbase_768_None_text_0_test.npy\n",
      "shape of y_train_distilled: (49126, 11), shape of y_test_distilled: (11723, 11)\n",
      "Using text models: []\n",
      "Transformed training data shape: (49126, 104)\n",
      "Transformed test data shape: (11723, 104)\n",
      "Tappbert baseline: acc - 0.7896, f1 - 0.7868\n",
      "Evaluating version: soft\n",
      "(49126, 104) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 25960\n",
      "Ccp alpha paths, after filtering: 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211759113a194bf0aa89137fcc6c7c76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7677, f1 - 0.7303, con_acc - 0.8734, con_f1 - 0.8374\n",
      "Selected ccp_alpha: 2.4948467645463673e-05\n",
      "Number of nodes: 33\n",
      "Max depth: 10\n",
      "Evaluating version: distilled\n",
      "(49126, 104) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 1541\n",
      "Ccp alpha paths, after filtering: 1539\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3dab5b77eb44560b2d9a6b0186085fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/1539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7676, f1 - 0.7303, con_acc - 0.8734, con_f1 - 0.8374\n",
      "Selected ccp_alpha: 0.000139066857697742\n",
      "Number of nodes: 31\n",
      "Max depth: 10\n",
      "Using text models: ['BoW']\n",
      "Transformed training data shape: (49126, 504)\n",
      "Transformed test data shape: (11723, 504)\n",
      "Tappbert baseline: acc - 0.7896, f1 - 0.7868\n",
      "Evaluating version: soft\n",
      "(49126, 504) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 28583\n",
      "Ccp alpha paths, after filtering: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43fb85f1588a40eba3a08d7f2594de39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7737, f1 - 0.7308, con_acc - 0.8889, con_f1 - 0.8563\n",
      "Selected ccp_alpha: 1.054222327139895e-05\n",
      "Number of nodes: 55\n",
      "Max depth: 11\n",
      "Evaluating version: distilled\n",
      "(49126, 504) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 859\n",
      "Ccp alpha paths, after filtering: 858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afeadb5af1184587a327e61af21b0c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/858 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7940, f1 - 0.7901, con_acc - 0.9282, con_f1 - 0.9278\n",
      "Selected ccp_alpha: 0.00011698855132231559\n",
      "Number of nodes: 283\n",
      "Max depth: 24\n",
      "Using text models: ['BoNG']\n",
      "Transformed training data shape: (49126, 504)\n",
      "Transformed test data shape: (11723, 504)\n",
      "Tappbert baseline: acc - 0.7896, f1 - 0.7868\n",
      "Evaluating version: soft\n",
      "(49126, 504) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 27362\n",
      "Ccp alpha paths, after filtering: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82345ea3b2254d57bec097680972c81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7801, f1 - 0.7654, con_acc - 0.9029, con_f1 - 0.8946\n",
      "Selected ccp_alpha: 1.0596483121131335e-05\n",
      "Number of nodes: 53\n",
      "Max depth: 12\n",
      "Evaluating version: distilled\n",
      "(49126, 504) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 1116\n",
      "Ccp alpha paths, after filtering: 1115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78b2296564c04c0b9e49a98dab2afa26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/1115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7919, f1 - 0.7913, con_acc - 0.9186, con_f1 - 0.9191\n",
      "Selected ccp_alpha: 0.00017119872736414432\n",
      "Number of nodes: 121\n",
      "Max depth: 17\n",
      "Using text models: ['LDA']\n",
      "Transformed training data shape: (49126, 184)\n",
      "Transformed test data shape: (11723, 184)\n",
      "Tappbert baseline: acc - 0.7896, f1 - 0.7868\n",
      "Evaluating version: soft\n",
      "(49126, 184) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 28369\n",
      "Ccp alpha paths, after filtering: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd93685db844f35a07f0f8f45661785",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7721, f1 - 0.7297, con_acc - 0.8839, con_f1 - 0.8512\n",
      "Selected ccp_alpha: 1.0767096483898792e-05\n",
      "Number of nodes: 53\n",
      "Max depth: 11\n",
      "Evaluating version: distilled\n",
      "(49126, 184) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 1140\n",
      "Ccp alpha paths, after filtering: 1139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87bd93fc1ca34d1da4d0af5bb8ca5dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/1139 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7673, f1 - 0.7465, con_acc - 0.8674, con_f1 - 0.8531\n",
      "Selected ccp_alpha: 0.00035000649973367364\n",
      "Number of nodes: 77\n",
      "Max depth: 12\n",
      "Using text models: ['BoW', 'BoNG', 'LDA']\n",
      "Transformed training data shape: (49126, 984)\n",
      "Transformed test data shape: (11723, 984)\n",
      "Tappbert baseline: acc - 0.7896, f1 - 0.7868\n",
      "Evaluating version: soft\n",
      "(49126, 984) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 28971\n",
      "Ccp alpha paths, after filtering: 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e889119f1eb45b99877d5e328d7502d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7737, f1 - 0.7308, con_acc - 0.8889, con_f1 - 0.8563\n",
      "Selected ccp_alpha: 1.0542223271399045e-05\n",
      "Number of nodes: 55\n",
      "Max depth: 11\n",
      "Evaluating version: distilled\n",
      "(49126, 984) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 805\n",
      "Ccp alpha paths, after filtering: 804\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b75b1f7295f94a57a08579fbc68743f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/804 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7894, f1 - 0.7857, con_acc - 0.9151, con_f1 - 0.9144\n",
      "Selected ccp_alpha: 7.313959198250084e-05\n",
      "Number of nodes: 1083\n",
      "Max depth: 26\n",
      "Loading distilled labels for run 1...\n",
      "Distillation paths: data/distillation/bpi_2012_enriched_filtered_A/y_BERTbase_768_None_text_1_train.npy data/distillation/bpi_2012_enriched_filtered_A/y_BERTbase_768_None_text_1_test.npy\n",
      "shape of y_train_distilled: (49126, 11), shape of y_test_distilled: (11723, 11)\n",
      "Using text models: []\n",
      "Transformed training data shape: (49126, 104)\n",
      "Transformed test data shape: (11723, 104)\n",
      "Tappbert baseline: acc - 0.7894, f1 - 0.7930\n",
      "Evaluating version: soft\n",
      "(49126, 104) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 24025\n",
      "Ccp alpha paths, after filtering: 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7267b884f76a41499f0e0972e2cc9481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7769, f1 - 0.7408, con_acc - 0.8398, con_f1 - 0.7978\n",
      "Selected ccp_alpha: 3.4410822100691786e-05\n",
      "Number of nodes: 39\n",
      "Max depth: 13\n",
      "Evaluating version: distilled\n",
      "(49126, 104) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 1522\n",
      "Ccp alpha paths, after filtering: 1519\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50921633f353438dae11fa0197b095db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/1519 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distilled: acc - 0.7478, f1 - 0.7200, con_acc - 0.8754, con_f1 - 0.8369\n",
      "Selected ccp_alpha: 0.0001798674382041199\n",
      "Number of nodes: 29\n",
      "Max depth: 10\n",
      "Using text models: ['BoW']\n",
      "Transformed training data shape: (49126, 504)\n",
      "Transformed test data shape: (11723, 504)\n",
      "Tappbert baseline: acc - 0.7894, f1 - 0.7930\n",
      "Evaluating version: soft\n",
      "(49126, 504) (49126, 11)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 26151\n",
      "Ccp alpha paths, after filtering: 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90eaba1088de4f00bbb91a2fceb0b60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soft: acc - 0.7971, f1 - 0.8006, con_acc - 0.9237, con_f1 - 0.9232\n",
      "Selected ccp_alpha: 1.0003964602014569e-05\n",
      "Number of nodes: 93\n",
      "Max depth: 15\n",
      "Evaluating version: distilled\n",
      "(49126, 504) (49126,)\n",
      "skip_pruning False\n",
      "Ccp alpha paths: 879\n",
      "Ccp alpha paths, after filtering: 878\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd8697e3207640c1810337a0cc9bd5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CCP pruning search:   0%|          | 0/878 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 150\u001b[39m\n\u001b[32m    148\u001b[39m \u001b[38;5;28mprint\u001b[39m(X_train.shape, train_labels.shape)\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# Train + evaluate\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m results = \u001b[43mevaluate_distillation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstudent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    153\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_test_distilled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m    \u001b[49m\u001b[43my_save_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_y_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_save_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstart_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskip_pruning\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskip_pruning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# Save results\u001b[39;00m\n\u001b[32m    165\u001b[39m meta = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    166\u001b[39m     folder_name=folder_name,\n\u001b[32m    167\u001b[39m     description=desc,\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     run_id=run_id,\n\u001b[32m    173\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/reddit-mining/src/distillation.py:15\u001b[39m, in \u001b[36mevaluate_distillation\u001b[39m\u001b[34m(model, X_train, X_test, y_train, y_test, y_test_distilled, description, output, y_save_path, model_save_path, start_alpha, skip_pruning)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_text, _tree\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/tree/_classes.py:1024\u001b[39m, in \u001b[36mDecisionTreeClassifier.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m    993\u001b[39m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    994\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m, check_input=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m    995\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[32m    996\u001b[39m \n\u001b[32m    997\u001b[39m \u001b[33;03m    Parameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1021\u001b[39m \u001b[33;03m        Fitted estimator.\u001b[39;00m\n\u001b[32m   1022\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1024\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1028\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1029\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1030\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/conda/lib/python3.12/site-packages/sklearn/tree/_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "update_repository()\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tapp.text_encoder import BoWTextEncoder, BoNGTextEncoder, LDATextEncoder, BERTbaseTextEncoder\n",
    "from tapp.log_encoder import LogEncoder\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from tapp.tapp_model import _get_event_labels\n",
    "from distillation import (\n",
    "    get_distillation_paths,\n",
    "    get_evaluation_paths,\n",
    "    evaluate_distillation,\n",
    "    analyze_text_splits,\n",
    "    prepare_text_feature_datasets,\n",
    "    concatenate_text_feature_datasets,\n",
    "    get_feature_datasets,\n",
    "    save_evaluation_results,\n",
    "    tree_to_str,\n",
    ")\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "def get_student_model(target_type=\"original\", ccp_alpha=0.00001, random_state=0, **kwargs):\n",
    "    if target_type == \"soft\":\n",
    "        return DecisionTreeRegressor(random_state=random_state, ccp_alpha=ccp_alpha, **kwargs)\n",
    "    else:\n",
    "        return DecisionTreeClassifier(random_state=random_state, ccp_alpha=ccp_alpha, **kwargs)\n",
    "\n",
    "text_model_tapp = BERTbaseTextEncoder(encoding_length=768, language=\"english\")\n",
    "text_models = [\n",
    "    BoWTextEncoder(encoding_length=50, language=\"english\"),\n",
    "    BoNGTextEncoder(n=2, encoding_length=50, language=\"english\"),\n",
    "    LDATextEncoder(encoding_length=10, language=\"english\"),\n",
    "]\n",
    "model_names = [[], [\"BoW\"], [\"BoNG\"], [\"LDA\"], [\"BoW\", \"BoNG\", \"LDA\"]]\n",
    "runs = 3\n",
    "start_alpha = 0.00001\n",
    "end_alpha = 0.001\n",
    "skip_pruning = False\n",
    "folder_names = [\"bpi_2012_enriched_special_filtered_A\"]\n",
    "folder_names = [\"bpi_2012_enriched_filtered_A\"]\n",
    "folder_names = [\"werk\"]\n",
    "folder_names = [\"bpi_2012_enriched_filtered_A\",\"werk\"]\n",
    "\n",
    "# ----------------------------\n",
    "# Load distilled labels\n",
    "# ----------------------------\n",
    "for folder_name in folder_names:\n",
    "    print(\"Evaluating folder:\", folder_name)\n",
    "    if folder_name == \"werk\":\n",
    "        path = \"./data/werk.xes\"\n",
    "        data_attributes = [\"age\", \"gender\"]\n",
    "        text_attribute = \"question\"\n",
    "        k = 10\n",
    "        text_model_tapp = BERTbaseTextEncoder(encoding_length=768, language=\"english\")\n",
    "    elif \"bpi\" in folder_name:\n",
    "        path = f\"./data/{folder_name}.xes\"\n",
    "        data_attributes = []\n",
    "        text_attribute = \"binary_flag\" if \"special\" in folder_name else \"text\"\n",
    "        k = 8\n",
    "        text_model_tapp = BERTbaseTextEncoder(encoding_length=768, language=\"english\")\n",
    "\n",
    "    log = xes_importer.apply(path, variant=variant, parameters=parameters)\n",
    "    activities = _get_event_labels(log, \"concept:name\")\n",
    "    class_names = _get_event_labels(log, \"concept:name\")\n",
    "    class_names.append(\"END\")\n",
    "    split = len(log) // 5 * 4\n",
    "    print(\"Log split at index:\", split)\n",
    "    train_log = log[:split]\n",
    "    test_log = log[split:]\n",
    "    \n",
    "    for run_id in range(runs):\n",
    "        print(f\"Loading distilled labels for run {run_id}...\")\n",
    "        distillation_path_train, distillation_path_test = get_distillation_paths(folder_name, text_model_tapp, data_attributes, text_attribute, run_id)\n",
    "        print(\"Distillation paths:\", distillation_path_train, distillation_path_test)\n",
    "        y_train_distilled = np.load(distillation_path_train)\n",
    "        y_test_distilled = np.load(distillation_path_test)\n",
    "        print(f\"shape of y_train_distilled: {y_train_distilled.shape}, shape of y_test_distilled: {y_test_distilled.shape}\")\n",
    "        y_train_soft = y_train_distilled.copy()\n",
    "        y_test_soft = y_test_distilled.copy()\n",
    "        y_train_distilled = y_train_distilled.argmax(axis=1)\n",
    "        y_test_distilled = y_test_distilled.argmax(axis=1)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Evaluation loop\n",
    "        # ----------------------------\n",
    "\n",
    "        for model_names_subset in model_names:\n",
    "            print(f\"Using text models: {model_names_subset}\")\n",
    "            train_dataset, test_dataset = get_feature_datasets(\n",
    "                folder_name,\n",
    "                text_models,\n",
    "                log,\n",
    "                train_log,\n",
    "                test_log,\n",
    "                k=k,\n",
    "                data_attributes=data_attributes,\n",
    "                text_attribute=text_attribute,\n",
    "            )\n",
    "            y_train = train_dataset[\"y\"].argmax(axis=1)\n",
    "            y_test = test_dataset[\"y\"].argmax(axis=1)\n",
    "            X_train, features = concatenate_text_feature_datasets(train_dataset, model_names_subset)\n",
    "            X_test, _ = concatenate_text_feature_datasets(test_dataset, model_names_subset)\n",
    "            print(\"Transformed training data shape:\", X_train.shape)\n",
    "            print(\"Transformed test data shape:\", X_test.shape)\n",
    "\n",
    "            # evaluate baseline\n",
    "            meta = dict(\n",
    "                folder_name=folder_name,\n",
    "                description=\"baseline\",\n",
    "                data_attributes=data_attributes,\n",
    "                text_attribute=text_attribute,\n",
    "                model_names=model_names_subset,\n",
    "                k=k,\n",
    "                run_id=run_id,\n",
    "            )\n",
    "\n",
    "            acc_tp = accuracy_score(y_test, y_test_distilled)\n",
    "            f1_score_tp = f1_score(y_test, y_test_distilled, average=\"weighted\")\n",
    "            print(f\"Tappbert baseline: acc - {acc_tp:.4f}, f1 - {f1_score_tp:.4f}\")\n",
    "            results = {\"accuracy\": acc_tp, \"f1_score\": f1_score_tp, \"con_accuracy\": 1.0, \"con_f1_score\": 1.0, \"num_nodes\": 0, \"max_depth\": 0, \"ccp_alpha\": 0.0, \"avg_path_length\": 0.0}\n",
    "\n",
    "            meta.update(results)\n",
    "\n",
    "            save_evaluation_results(**meta)\n",
    "\n",
    "            for version, train_labels in [\n",
    "                    #(\"original\", y_train),\n",
    "                    (\"soft\", y_train_soft),\n",
    "                    (\"distilled\", y_train_distilled),\n",
    "                ]:\n",
    "                print(f\"Evaluating version: {version}\")\n",
    "                desc = f\"{version}\"\n",
    "                model_path, model_str_path, model_features_path, model_y_path = get_evaluation_paths(\n",
    "                    folder_name,\n",
    "                    version,\n",
    "                    model_names_subset=model_names_subset,\n",
    "                    data_attributes=data_attributes,\n",
    "                    text_attribute=text_attribute,\n",
    "                    run_id=run_id,\n",
    "                )\n",
    "\n",
    "                student = get_student_model(target_type=version)\n",
    "\n",
    "                print(X_train.shape, train_labels.shape)\n",
    "                # Train + evaluate\n",
    "                results = evaluate_distillation(\n",
    "                    student,\n",
    "                    X_train,\n",
    "                    X_test,\n",
    "                    train_labels,\n",
    "                    y_test,\n",
    "                    y_test_distilled,\n",
    "                    description=desc,\n",
    "                    y_save_path=model_y_path,\n",
    "                    model_save_path=model_path,\n",
    "                    start_alpha=start_alpha,\n",
    "                    end_alpha=end_alpha,\n",
    "                    skip_pruning=skip_pruning,\n",
    "                )\n",
    "\n",
    "                # Save results\n",
    "                meta = dict(\n",
    "                    folder_name=folder_name,\n",
    "                    description=desc,\n",
    "                    data_attributes=data_attributes,\n",
    "                    text_attribute=text_attribute,\n",
    "                    model_names=model_names_subset,\n",
    "                    k=k,\n",
    "                    run_id=run_id,\n",
    "                )\n",
    "\n",
    "                meta.update(results)\n",
    "\n",
    "                save_evaluation_results(**meta)\n",
    "\n",
    "\n",
    "print(\"Analysis complete.\")\n",
    "print(\"Done and dusted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16982b6",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24455898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', '', '8', '0', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', '', '8', '0', '0.6285933634735136', '0.5445184859041607', '0.9996587904120106', '0.9996590345983271', '15', '6', '0.0008562450573939325', '3.313486308965282']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', '', '8', '0', '0.6287639682675084', '0.5445985870293423', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW', '8', '0', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW', '8', '0', '0.6115328840740425', '0.5256469325526913', '0.9676703915380023', '0.9542277282793291', '13', '5', '0.0008562450573939324', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW', '8', '0', '0.6287639682675084', '0.5445782373745723', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoNG', '8', '0', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoNG', '8', '0', '0.6115328840740425', '0.5256469325526913', '0.9676703915380023', '0.9542277282793291', '13', '5', '0.0008562450573939328', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoNG', '8', '0', '0.6287639682675084', '0.5445782373745723', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'LDA', '8', '0', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'LDA', '8', '0', '0.6285933634735136', '0.5445184859041607', '0.9996587904120106', '0.9996590345983271', '15', '6', '0.0008562450573939322', '3.313486308965282']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'LDA', '8', '0', '0.6117034888680372', '0.5199939163637378', '0.9680116011259916', '0.9527918141859373', '9', '3', '0.06885513963707905', '2.43256845517359']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '0', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '0', '0.6115328840740425', '0.5256469325526913', '0.9676703915380023', '0.9542277282793291', '13', '5', '0.0008562450573939328', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '0', '0.6117034888680372', '0.5199939163637378', '0.9680116011259916', '0.9527918141859373', '9', '3', '0.06885513963707905', '2.43256845517359']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', '', '8', '1', '0.7100571526059882', '0.7026696293266168', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', '', '8', '1', '0.709289431033012', '0.6497585419748122', '0.7580824021154995', '0.6991925508798401', '29', '8', '1.2272124632050286e-05', '4.037362449884842']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', '', '8', '1', '0.6906935084875885', '0.6530220654655668', '0.7644800818903011', '0.7228402889880873', '27', '9', '0.00030377902494736764', '3.99872046404504']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW', '8', '1', '0.7100571526059882', '0.7026696293266168', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW', '8', '1', '0.7142369700588587', '0.7073173051818439', '0.8567772754414399', '0.8543226602500968', '55', '10', '1.0986108227223888e-05', '5.090079331229208']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW', '8', '1', '0.7166254371747847', '0.7086772616367399', '0.8737524524439136', '0.8729542962273573', '241', '14', '0.00018163428173728537', '6.835878188177087']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoNG', '8', '1', '0.7100571526059882', '0.7026696293266168', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoNG', '8', '1', '0.6746566578520856', '0.6594777837025778', '0.8020131365691376', '0.7775229072654686', '53', '10', '1.0658792036041779e-05', '4.915550626972618']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoNG', '8', '1', '0.711677898148938', '0.70416226802823', '0.8476499189627229', '0.8468596886948966', '181', '16', '0.00014899308377855358', '7.118314424635332']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'LDA', '8', '1', '0.7100571526059882', '0.7026696293266168', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'LDA', '8', '1', '0.6843811311097842', '0.6517046490377104', '0.7028917512582104', '0.6797369839959394', '65', '11', '1.0077013214301878e-05', '5.302652904546618']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'LDA', '8', '1', '0.6208308453467543', '0.5798863767012793', '0.6500895675168472', '0.6181856330832093', '629', '21', '0.00010753598951018231', '7.072762944638744']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '1', '0.7100571526059882', '0.7026696293266168', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '1', '0.7142369700588587', '0.7073360545365995', '0.8566919730444426', '0.8542417902662092', '65', '10', '1.0261847858162939e-05', '5.326964087690864']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '1', '0.6976030026443744', '0.6815324340303279', '0.779578606158833', '0.7731435335403205', '685', '17', '0.00011598979948594324', '7.625607779578607']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', '', '8', '2', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', '', '8', '2', '0.6117034888680372', '0.5257537334400575', '0.9678409963319969', '0.9543736483510074', '13', '5', '0.0008365257058657922', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', '', '8', '2', '0.6287639682675084', '0.5445782373745723', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW', '8', '2', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW', '8', '2', '0.6117034888680372', '0.5257537334400575', '0.9678409963319969', '0.9543736483510074', '13', '5', '0.0008365257058657921', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW', '8', '2', '0.6287639682675084', '0.5445782373745723', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoNG', '8', '2', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoNG', '8', '2', '0.6287639682675084', '0.5446299146024963', '0.9998293952060053', '0.9998294563420805', '15', '6', '0.0008365257058657921', '3.3133157041712873']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoNG', '8', '2', '0.6287639682675084', '0.5445985870293423', '0.9999146976030027', '0.9999146999561759', '11', '4', '5.088452034061167e-05', '2.7787255821888595']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'LDA', '8', '2', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'LDA', '8', '2', '0.6117034888680372', '0.5257537334400575', '0.9678409963319969', '0.9543736483510074', '13', '5', '0.0008365257058657922', '3.1949159771389577']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'LDA', '8', '2', '0.6117034888680372', '0.5199939163637378', '0.9680116011259916', '0.9527918141859373', '9', '3', '0.06885513963707905', '2.43256845517359']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'baseline', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '2', '0.6287639682675084', '0.5445995597274994', '1.0', '1.0']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'soft', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '2', '0.6287639682675084', '0.5446299146024963', '0.9998293952060053', '0.9998294563420805', '15', '6', '0.0008365257058657917', '3.3133157041712873']\n",
      "Writing row: ['bpi_2012_enriched_special_filtered_A', 'distilled', '', 'binary_flag', 'BoW,BoNG,LDA', '8', '2', '0.6117034888680372', '0.5199939163637378', '0.9680116011259916', '0.9527918141859373', '9', '3', '0.06885513963707905', '2.43256845517359']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import sys\n",
    "\n",
    "folder_path = \"./data/distillation\"\n",
    "input_name = \"evaluation_results.csv\"\n",
    "output_name = \"evaluation_results_bpi.csv\"\n",
    "in_path = os.path.join(folder_path, input_name)\n",
    "out_path = os.path.join(folder_path, output_name)\n",
    "\n",
    "K = 64  # number of data rows to remove AFTER header\n",
    "\n",
    "with open(in_path, \"r\", newline=\"\") as infile, \\\n",
    "     open(out_path, \"w\", newline=\"\") as outfile:\n",
    "    \n",
    "    reader = csv.reader(infile)\n",
    "    writer = csv.writer(outfile)\n",
    "\n",
    "    # Read and keep the header\n",
    "    header = next(reader, None)\n",
    "    writer.writerow(header)\n",
    "\n",
    "    # Skip the first K actual data rows\n",
    "    for _ in range(K):\n",
    "        next(reader, None)\n",
    "\n",
    "    # Write the remaining rows\n",
    "    for row in reader:\n",
    "        print(\"Writing row:\", row)\n",
    "        writer.writerow(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "487a57d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Performance Results ===\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=baseline, model=BoNG ===\n",
      "accuracy: 0.656 ± 0.047\n",
      "f1_score: 0.597 ± 0.091\n",
      "con_accuracy: 1.000 ± 0.000\n",
      "con_f1_score: 1.000 ± 0.000\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=baseline, model=BoW ===\n",
      "accuracy: 0.656 ± 0.047\n",
      "f1_score: 0.597 ± 0.091\n",
      "con_accuracy: 1.000 ± 0.000\n",
      "con_f1_score: 1.000 ± 0.000\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=baseline, model=BoW,BoNG,LDA ===\n",
      "accuracy: 0.656 ± 0.047\n",
      "f1_score: 0.597 ± 0.091\n",
      "con_accuracy: 1.000 ± 0.000\n",
      "con_f1_score: 1.000 ± 0.000\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=baseline, model=LDA ===\n",
      "accuracy: 0.656 ± 0.047\n",
      "f1_score: 0.597 ± 0.091\n",
      "con_accuracy: 1.000 ± 0.000\n",
      "con_f1_score: 1.000 ± 0.000\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=baseline, model=None ===\n",
      "accuracy: 0.656 ± 0.047\n",
      "f1_score: 0.597 ± 0.091\n",
      "con_accuracy: 1.000 ± 0.000\n",
      "con_f1_score: 1.000 ± 0.000\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoNG ===\n",
      "accuracy: 0.656 ± 0.048\n",
      "f1_score: 0.598 ± 0.092\n",
      "con_accuracy: 0.949 ± 0.088\n",
      "con_f1_score: 0.949 ± 0.088\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoW ===\n",
      "accuracy: 0.658 ± 0.051\n",
      "f1_score: 0.599 ± 0.095\n",
      "con_accuracy: 0.958 ± 0.073\n",
      "con_f1_score: 0.958 ± 0.073\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoW,BoNG,LDA ===\n",
      "accuracy: 0.640 ± 0.050\n",
      "f1_score: 0.574 ± 0.093\n",
      "con_accuracy: 0.905 ± 0.109\n",
      "con_f1_score: 0.893 ± 0.104\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=LDA ===\n",
      "accuracy: 0.615 ± 0.005\n",
      "f1_score: 0.540 ± 0.035\n",
      "con_accuracy: 0.862 ± 0.184\n",
      "con_f1_score: 0.841 ± 0.193\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=None ===\n",
      "accuracy: 0.649 ± 0.036\n",
      "f1_score: 0.581 ± 0.063\n",
      "con_accuracy: 0.921 ± 0.136\n",
      "con_f1_score: 0.908 ± 0.160\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoNG ===\n",
      "accuracy: 0.638 ± 0.033\n",
      "f1_score: 0.577 ± 0.072\n",
      "con_accuracy: 0.923 ± 0.106\n",
      "con_f1_score: 0.911 ± 0.117\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoW ===\n",
      "accuracy: 0.646 ± 0.059\n",
      "f1_score: 0.586 ± 0.105\n",
      "con_accuracy: 0.931 ± 0.064\n",
      "con_f1_score: 0.921 ± 0.058\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoW,BoNG,LDA ===\n",
      "accuracy: 0.652 ± 0.055\n",
      "f1_score: 0.593 ± 0.100\n",
      "con_accuracy: 0.941 ± 0.075\n",
      "con_f1_score: 0.936 ± 0.074\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=LDA ===\n",
      "accuracy: 0.642 ± 0.038\n",
      "f1_score: 0.574 ± 0.068\n",
      "con_accuracy: 0.890 ± 0.163\n",
      "con_f1_score: 0.878 ± 0.173\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=None ===\n",
      "accuracy: 0.650 ± 0.052\n",
      "f1_score: 0.573 ± 0.067\n",
      "con_accuracy: 0.909 ± 0.131\n",
      "con_f1_score: 0.884 ± 0.162\n",
      "\n",
      "=== Complexity Results ===\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoNG ===\n",
      "num_nodes: 67.667 ± 98.150\n",
      "max_depth: 8.000 ± 6.928\n",
      "avg_path_length: 4.225 ± 2.505\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoW ===\n",
      "num_nodes: 87.667 ± 132.791\n",
      "max_depth: 7.333 ± 5.774\n",
      "avg_path_length: 4.131 ± 2.342\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=BoW,BoNG,LDA ===\n",
      "num_nodes: 234.333 ± 390.289\n",
      "max_depth: 7.667 ± 8.083\n",
      "avg_path_length: 4.164 ± 2.998\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=LDA ===\n",
      "num_nodes: 215.667 ± 357.957\n",
      "max_depth: 9.000 ± 10.392\n",
      "avg_path_length: 3.979 ± 2.679\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=distilled, model=None ===\n",
      "num_nodes: 16.333 ± 9.238\n",
      "max_depth: 5.667 ± 2.887\n",
      "avg_path_length: 3.185 ± 0.704\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoNG ===\n",
      "num_nodes: 27.000 ± 22.539\n",
      "max_depth: 7.000 ± 2.646\n",
      "avg_path_length: 3.808 ± 0.961\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoW ===\n",
      "num_nodes: 27.000 ± 24.249\n",
      "max_depth: 6.667 ± 2.887\n",
      "avg_path_length: 3.827 ± 1.094\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=BoW,BoNG,LDA ===\n",
      "num_nodes: 31.000 ± 29.462\n",
      "max_depth: 7.000 ± 2.646\n",
      "avg_path_length: 3.945 ± 1.198\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=LDA ===\n",
      "num_nodes: 31.000 ± 29.462\n",
      "max_depth: 7.333 ± 3.215\n",
      "avg_path_length: 3.937 ± 1.184\n",
      "\n",
      "=== Group: folder=bpi_2012_enriched_special_filtered_A, description=soft, model=None ===\n",
      "num_nodes: 19.000 ± 8.718\n",
      "max_depth: 6.333 ± 1.528\n",
      "avg_path_length: 3.515 ± 0.456\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to your CSV\n",
    "csv_folder = \"./data/distillation\"\n",
    "csv_file = \"evaluation_results_bpi.csv\"\n",
    "csv_path = os.path.join(csv_folder, csv_file)\n",
    "\n",
    "# Read CSV into DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Columns to compute stats for\n",
    "metric_cols = [\"accuracy\", \"f1_score\", \"con_accuracy\", \"con_f1_score\"]\n",
    "complexity_cols = [\"num_nodes\", \"max_depth\", \"avg_path_length\"]\n",
    "\n",
    "# Group by the required columns\n",
    "df[\"model_names\"] = df[\"model_names\"].replace(\"\", \"None\").fillna(\"None\")\n",
    "grouped = df.groupby([\"folder_name\", \"description\", \"model_names\"])\n",
    "\n",
    "# Process each group\n",
    "print(\"=== Performance Results ===\")\n",
    "for group_keys, group_df in grouped:\n",
    "    folder, desc, model = group_keys\n",
    "    print(f\"\\n=== Group: folder={folder}, description={desc}, model={model} ===\")\n",
    "\n",
    "    for col in metric_cols:\n",
    "        mean_val = group_df[col].mean()\n",
    "        std_val = group_df[col].std()\n",
    "\n",
    "        # Format: .xxx+-.xxx (rounded to 3 decimals)\n",
    "        formatted = f\"{mean_val:.3f} ± {std_val:.3f}\"\n",
    "\n",
    "        print(f\"{col}: {formatted}\")\n",
    "\n",
    "print(\"\\n=== Complexity Results ===\")\n",
    "for group_keys, group_df in grouped:\n",
    "    folder, desc, model = group_keys\n",
    "    if desc == \"baseline\":\n",
    "        continue\n",
    "    print(f\"\\n=== Group: folder={folder}, description={desc}, model={model} ===\")\n",
    "\n",
    "    for col in complexity_cols:\n",
    "        mean_val = group_df[col].mean()\n",
    "        std_val = group_df[col].std()\n",
    "\n",
    "        # Format: .xxx+-.xxx (rounded to 3 decimals)\n",
    "        formatted = f\"{mean_val:.3f} ± {std_val:.3f}\"\n",
    "\n",
    "        print(f\"{col}: {formatted}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe1ca8c",
   "metadata": {},
   "source": [
    "## Plot Average Path Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16333f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from distillation import (\n",
    "    get_distillation_paths,\n",
    "    get_evaluation_paths,\n",
    "    get_feature_datasets,\n",
    "    concatenate_text_feature_datasets,\n",
    ")\n",
    "text_models = [\n",
    "    BoWTextEncoder(encoding_length=50, language=\"english\"),\n",
    "    BoNGTextEncoder(n=2, encoding_length=50, language=\"english\"),\n",
    "    LDATextEncoder(encoding_length=10, language=\"english\"),\n",
    "]\n",
    "model_names_soft = [[], [\"BoW\"], [\"BoNG\"], [\"LDA\"], [\"BoW\", \"BoNG\", \"LDA\"]]\n",
    "model_names_hard = [[], [\"BoW\"], [\"BoNG\"], [\"LDA\"], [\"BoW\", \"BoNG\", \"LDA\"]]\n",
    "folder_names = [\"bpi_2012_enriched_filtered_A\", \"werk\"]\n",
    "runs = 3\n",
    "\n",
    "for folder_name in folder_names:\n",
    "    print(\"Evaluating folder:\", folder_name)\n",
    "    if folder_name == \"werk\":\n",
    "        path = \"./data/werk.xes\"\n",
    "        data_attributes = [\"age\", \"gender\"]\n",
    "        text_attribute = \"question\"\n",
    "        k = 10\n",
    "    elif \"bpi\" in folder_name:\n",
    "        path = f\"./data/{folder_name}.xes\"\n",
    "        data_attributes = []\n",
    "        text_attribute = \"binary_flag\" if \"special\" in folder_name else \"text\"\n",
    "        k = 8\n",
    "\n",
    "    train_dataset, test_dataset = get_feature_datasets(\n",
    "        folder_name,\n",
    "        text_models,\n",
    "        log,\n",
    "        None,\n",
    "        None,\n",
    "        k=k,\n",
    "        data_attributes=data_attributes,\n",
    "        text_attribute=text_attribute,\n",
    "    )\n",
    "    \n",
    "    for soft_model_names_subset in model_names_soft:\n",
    "        for hard_model_names_subset in model_names_hard:\n",
    "            all_soft_decisions = []\n",
    "            all_hard_decisions = []\n",
    "            for run_id in range(runs):\n",
    "                print(f\"Using text models: soft - {soft_model_names_subset}, hard - {hard_model_names_subset}\")\n",
    "                X_test_soft, _ = concatenate_text_feature_datasets(test_dataset, soft_model_names_subset)\n",
    "                X_test_hard, _ = concatenate_text_feature_datasets(test_dataset, hard_model_names_subset)\n",
    "\n",
    "                hard_model_path, _, _, _ = get_evaluation_paths(\n",
    "                    folder_name,\n",
    "                    \"hard\",\n",
    "                    model_names_subset=hard_model_names_subset,\n",
    "                    data_attributes=data_attributes,\n",
    "                    text_attribute=text_attribute,\n",
    "                    run_id=run_id,\n",
    "                )\n",
    "\n",
    "                soft_model_path, _, _, _ = get_evaluation_paths(\n",
    "                    folder_name,\n",
    "                    \"soft\",\n",
    "                    model_names_subset=soft_model_names_subset,\n",
    "                    data_attributes=data_attributes,\n",
    "                    text_attribute=text_attribute,\n",
    "                    run_id=run_id,\n",
    "                )\n",
    "\n",
    "                with open(soft_model_path, \"rb\") as f:\n",
    "                    soft_model = pickle.load(f)\n",
    "                with open(hard_model_path, \"rb\") as f:\n",
    "                    hard_model = pickle.load(f)\n",
    "\n",
    "                soft_decisions = soft_model.decision_path(X_test_soft)\n",
    "                all_soft_decisions.append(soft_decisions)\n",
    "                hard_decisions = hard_model.decision_path(X_test_hard)\n",
    "                all_hard_decisions.append(hard_decisions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
